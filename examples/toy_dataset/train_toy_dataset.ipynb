{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from NEXT_graphNN.utils.data_loader import weights_loss, load_graph_data, split_dataset, LabelType, NetArchitecture\n",
    "from NEXT_graphNN.utils.train_utils import train_net, predict_gen, train_one_epoch\n",
    "\n",
    "from torch_geometric.nn.models import GraphUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeltype = LabelType.Segmentation\n",
    "netarch   = NetArchitecture.GraphUNet\n",
    "\n",
    "## Net architecture variables\n",
    "init_features = 1 \n",
    "hidden_dim    = 20\n",
    "nclass        = 2\n",
    "depth         = 4\n",
    "pool_ratio    = 0.3\n",
    "\n",
    "# Net weights to load\n",
    "saved_weights = None\n",
    "# saved_weights = 'path/to/trained/weights' ##would load certain weights for the net\n",
    "\n",
    "## Data\n",
    "train_perc = 0.9\n",
    "\n",
    "## Train\n",
    "nepoch          = 1\n",
    "train_batch     = 50\n",
    "valid_batch     = 50\n",
    "checkpoint_dir  = '/mnt/lustre/scratch/nlsas/home/usc/ie/mpm/NEXT100/graph_toy_experiment/train/checkpoints/'\n",
    "tensorboard_dir = '/mnt/lustre/scratch/nlsas/home/usc/ie/mpm/NEXT100/graph_toy_experiment/train/tensorboard/'\n",
    "num_workers     = 3\n",
    "#Loss\n",
    "LossType        = 'CrossEntropyLoss'\n",
    "#Optimizer\n",
    "lr           = 1e-2\n",
    "betas        = (0.9, 0.999)\n",
    "eps          = 1e-6\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = sorted(glob.glob('/mnt/lustre/scratch/nlsas/home/usc/ie/mpm/NEXT100/graph_toy_experiment/prod/*.pt'), \n",
    "              key = lambda x: int(re.findall(r'\\d+', x)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [graph for f in path for graph in torch.load(f) if graph.edge_index.numel() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GraphUNet(init_features, \n",
    "                hidden_dim,\n",
    "                nclass, \n",
    "                depth,\n",
    "                pool_ratio).to(device)\n",
    "\n",
    "model_uses_batch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = split_dataset(data, train_perc=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights_loss(train_data, labeltype, nclass = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(weight = torch.Tensor(weights).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                                     lr = lr,\n",
    "                                     betas = betas,\n",
    "                                     eps = eps,\n",
    "                                     weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb Celda 11\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_net(nepoch \u001b[39m=\u001b[39;49m nepoch,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                   train_data \u001b[39m=\u001b[39;49m train_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                   valid_data \u001b[39m=\u001b[39;49m valid_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                   train_batch_size \u001b[39m=\u001b[39;49m train_batch,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                   valid_batch_size \u001b[39m=\u001b[39;49m valid_batch,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                   net \u001b[39m=\u001b[39;49m net,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                   device \u001b[39m=\u001b[39;49m device,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                   optimizer \u001b[39m=\u001b[39;49m optimizer,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                   criterion \u001b[39m=\u001b[39;49m criterion,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                   label_type \u001b[39m=\u001b[39;49m labeltype,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                   nclass \u001b[39m=\u001b[39;49m nclass,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                   model_uses_batch \u001b[39m=\u001b[39;49m model_uses_batch,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                   checkpoint_dir  \u001b[39m=\u001b[39;49m checkpoint_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                   tensorboard_dir \u001b[39m=\u001b[39;49m tensorboard_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                   num_workers \u001b[39m=\u001b[39;49m num_workers)\n",
      "File \u001b[0;32m/mnt/netapp2/Home_FT2/home/usc/ie/mpm/NEXT_graphs/NEXT_graphNN/utils/train_utils.py:179\u001b[0m, in \u001b[0;36mtrain_net\u001b[0;34m(nepoch, train_data, valid_data, train_batch_size, valid_batch_size, net, device, optimizer, criterion, label_type, nclass, model_uses_batch, checkpoint_dir, tensorboard_dir, num_workers)\u001b[0m\n\u001b[1;32m    177\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(tensorboard_dir)\n\u001b[1;32m    178\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nepoch):\n\u001b[0;32m--> 179\u001b[0m     train_loss, train_met \u001b[39m=\u001b[39m train_one_epoch(i, net, loader_train, device, optimizer, criterion, label_type, nclass \u001b[39m=\u001b[39;49m nclass, model_uses_batch \u001b[39m=\u001b[39;49m model_uses_batch)\n\u001b[1;32m    180\u001b[0m     valid_loss, valid_met \u001b[39m=\u001b[39m valid_one_epoch(net, loader_valid, device, criterion, label_type, nclass \u001b[39m=\u001b[39m nclass, model_uses_batch \u001b[39m=\u001b[39m model_uses_batch)\n\u001b[1;32m    182\u001b[0m     \u001b[39mif\u001b[39;00m valid_loss \u001b[39m<\u001b[39m start_loss:\n",
      "File \u001b[0;32m/mnt/netapp2/Home_FT2/home/usc/ie/mpm/NEXT_graphs/NEXT_graphNN/utils/train_utils.py:61\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_id, model, loader, device, optimizer, loss_fn, label_type, nclass, model_uses_batch)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m# Pass the data to the model\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m model_uses_batch:\n\u001b[0;32m---> 61\u001b[0m     out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(batch\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mfloat), batch\u001b[39m.\u001b[39;49medge_index, batch\u001b[39m.\u001b[39;49mbatch) \n\u001b[1;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(batch\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat), batch\u001b[39m.\u001b[39medge_index)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch_geometric/nn/models/graph_unet.py:89\u001b[0m, in \u001b[0;36mGraphUNet.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     86\u001b[0m     batch \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39mnew_zeros(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n\u001b[1;32m     87\u001b[0m edge_weight \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mnew_ones(edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 89\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown_convs[\u001b[39m0\u001b[39;49m](x, edge_index, edge_weight)\n\u001b[1;32m     90\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(x)\n\u001b[1;32m     92\u001b[0m xs \u001b[39m=\u001b[39m [x]\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:177\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m gcn_norm(  \u001b[39m# yapf: disable\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         edge_index, edge_weight, x\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim),\n\u001b[1;32m    178\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimproved, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_self_loops, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow, x\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached:\n\u001b[1;32m    180\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index \u001b[39m=\u001b[39m (edge_index, edge_weight)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "train_net(nepoch = nepoch,\n",
    "                  train_data = train_data,\n",
    "                  valid_data = valid_data,\n",
    "                  train_batch_size = train_batch,\n",
    "                  valid_batch_size = valid_batch,\n",
    "                  net = net,\n",
    "                  device = device,\n",
    "                  optimizer = optimizer,\n",
    "                  criterion = criterion,\n",
    "                  label_type = labeltype,\n",
    "                  nclass = nclass,\n",
    "                  model_uses_batch = model_uses_batch,\n",
    "                  checkpoint_dir  = checkpoint_dir,\n",
    "                  tensorboard_dir = tensorboard_dir,\n",
    "                  num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "loader_train = DataLoader(train_data,\n",
    "                            batch_size = train_batch,\n",
    "                            shuffle = True,\n",
    "                            num_workers = num_workers,\n",
    "                            drop_last = True,\n",
    "                            pin_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.loader.dataloader.DataLoader at 0x1547ae4c6250>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader_train:\n",
    "\n",
    "    # Pass the batch to device (cuda)\n",
    "    batch = batch.to(device)\n",
    "\n",
    "    # Zero grad the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1006])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1006, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x.type(torch.float).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1396])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb Celda 18\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m GCNConv(\u001b[39m1\u001b[39;49m, \u001b[39m20\u001b[39;49m)(batch\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mfloat)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m), batch\u001b[39m.\u001b[39;49medge_index)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:195\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m             edge_index \u001b[39m=\u001b[39m cache\n\u001b[0;32m--> 195\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin(x)\n\u001b[1;32m    197\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m    198\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, edge_weight\u001b[39m=\u001b[39medge_weight,\n\u001b[1;32m    199\u001b[0m                      size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch_geometric/nn/dense/linear.py:136\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    132\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m        x (Tensor): The features.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)"
     ]
    }
   ],
   "source": [
    "GCNConv(1, 20)(batch.x.type(torch.float).unsqueeze(1), batch.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb Celda 16\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m out \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mforward(batch\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mfloat), batch\u001b[39m.\u001b[39;49medge_index, batch\u001b[39m.\u001b[39;49mbatch)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch_geometric/nn/models/graph_unet.py:89\u001b[0m, in \u001b[0;36mGraphUNet.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     86\u001b[0m     batch \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39mnew_zeros(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n\u001b[1;32m     87\u001b[0m edge_weight \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mnew_ones(edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 89\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown_convs[\u001b[39m0\u001b[39;49m](x, edge_index, edge_weight)\n\u001b[1;32m     90\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(x)\n\u001b[1;32m     92\u001b[0m xs \u001b[39m=\u001b[39m [x]\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:177\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m gcn_norm(  \u001b[39m# yapf: disable\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         edge_index, edge_weight, x\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim),\n\u001b[1;32m    178\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimproved, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_self_loops, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow, x\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached:\n\u001b[1;32m    180\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index \u001b[39m=\u001b[39m (edge_index, edge_weight)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "out = net.forward(batch.x.type(torch.float), batch.edge_index, batch.batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb Celda 14\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mperez/NEXT/NEXT_graphs/examples/toy_dataset/train_toy_dataset.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_one_epoch(\u001b[39m0\u001b[39;49m, net, loader_train, device, optimizer, criterion, labeltype, nclass \u001b[39m=\u001b[39;49m nclass, model_uses_batch \u001b[39m=\u001b[39;49m model_uses_batch)\n",
      "File \u001b[0;32m/mnt/netapp2/Home_FT2/home/usc/ie/mpm/NEXT_graphs/NEXT_graphNN/utils/train_utils.py:61\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_id, model, loader, device, optimizer, loss_fn, label_type, nclass, model_uses_batch)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m# Pass the data to the model\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m model_uses_batch:\n\u001b[0;32m---> 61\u001b[0m     out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(batch\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mfloat), batch\u001b[39m.\u001b[39;49medge_index, batch\u001b[39m.\u001b[39;49mbatch) \n\u001b[1;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(batch\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat), batch\u001b[39m.\u001b[39medge_index)\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch_geometric/nn/models/graph_unet.py:89\u001b[0m, in \u001b[0;36mGraphUNet.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     86\u001b[0m     batch \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39mnew_zeros(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n\u001b[1;32m     87\u001b[0m edge_weight \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mnew_ones(edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 89\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown_convs[\u001b[39m0\u001b[39;49m](x, edge_index, edge_weight)\n\u001b[1;32m     90\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(x)\n\u001b[1;32m     92\u001b[0m xs \u001b[39m=\u001b[39m [x]\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ie/mpm/conda/envs/3.8-pytorch-env/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:177\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m gcn_norm(  \u001b[39m# yapf: disable\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         edge_index, edge_weight, x\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim),\n\u001b[1;32m    178\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimproved, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_self_loops, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow, x\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached:\n\u001b[1;32m    180\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index \u001b[39m=\u001b[39m (edge_index, edge_weight)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "train_one_epoch(0, net, loader_train, device, optimizer, criterion, labeltype, nclass = nclass, model_uses_batch = model_uses_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
