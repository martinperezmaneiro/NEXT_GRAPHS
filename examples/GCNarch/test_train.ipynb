{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB developing and testing train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import tables as tb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('/home/usc/ie/mpm/NEXT_graphs')\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from NEXT_graphNN.networks.architectures import GCNClass\n",
    "from NEXT_graphNN.utils.train_utils import predict_gen, Metrics\n",
    "from NEXT_graphNN.utils.data_loader import LabelType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/mnt/lustre/scratch/nlsas/home/usc/ie/mpm/NEXT100/data/pressure_topology/1bar_1cm/dataset_1bar_graph_nn_all_1cm.pt'\n",
    "label_type = LabelType.Classification\n",
    "\n",
    "init_features = 4\n",
    "nclass = 2\n",
    "\n",
    "nconv = 4\n",
    "mult_feat_per_conv = 2\n",
    "dropout_prob = 0.1\n",
    "\n",
    "device = 'cpu'\n",
    "pred_batch = 64\n",
    "saved_weights = '/mnt/lustre/scratch/nlsas/home/usc/ie/mpm/NEXT100/data/pressure_topology/1bar_1cm/gpu_train/checkpoints/net_checkpoint_58.pth.tar'\n",
    "\n",
    "outfile = '/mnt/lustre/scratch/nlsas/home/usc/ie/mpm/NEXT100/data/pressure_topology/1bar_1cm/gpu_train/test_pred_nb.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNClass(init_features,\n",
    "                 nclass, \n",
    "                 nconv, \n",
    "                 mult_feat_per_conv = mult_feat_per_conv, \n",
    "                 dropout_prob = dropout_prob).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(data_file)\n",
    "train_data, valid_data, test_data = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce some output before loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_test = DataLoader(test_data,\n",
    "                         batch_size = pred_batch,\n",
    "                         shuffle = False,\n",
    "                         num_workers = 1,\n",
    "                         drop_last = False,\n",
    "                         pin_memory = False)\n",
    "    \n",
    "model.eval()\n",
    "softmax = torch.nn.Softmax(dim = 1)\n",
    "with torch.autograd.no_grad():\n",
    "    for batch in loader_test:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        out = model.forward(batch)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59533364, 0.40466633],\n",
       "       [0.59526145, 0.4047385 ],\n",
       "       [0.6207845 , 0.3792155 ],\n",
       "       [0.59603935, 0.4039607 ],\n",
       "       [0.59543294, 0.40456706],\n",
       "       [0.59554654, 0.40445346],\n",
       "       [0.6003027 , 0.39969733],\n",
       "       [0.5950027 , 0.4049972 ],\n",
       "       [0.633676  , 0.36632398],\n",
       "       [0.59578425, 0.40421566],\n",
       "       [0.59642017, 0.40357983],\n",
       "       [0.59646934, 0.40353066],\n",
       "       [0.63771695, 0.36228308],\n",
       "       [0.59522706, 0.40477285],\n",
       "       [0.5957497 , 0.40425032],\n",
       "       [0.59569097, 0.40430912],\n",
       "       [0.59544593, 0.4045541 ],\n",
       "       [0.59714395, 0.402856  ],\n",
       "       [0.59543747, 0.40456256],\n",
       "       [0.59579533, 0.4042047 ],\n",
       "       [0.6260353 , 0.3739647 ],\n",
       "       [0.5974554 , 0.4025446 ],\n",
       "       [0.62461823, 0.3753818 ],\n",
       "       [0.51765466, 0.4823453 ],\n",
       "       [0.6069003 , 0.3930998 ],\n",
       "       [0.59518623, 0.4048138 ],\n",
       "       [0.626395  , 0.37360507],\n",
       "       [0.5961277 , 0.4038723 ],\n",
       "       [0.62609535, 0.3739047 ],\n",
       "       [0.5957452 , 0.40425488],\n",
       "       [0.5959694 , 0.40403062],\n",
       "       [0.59542036, 0.40457967],\n",
       "       [0.59351104, 0.40648893],\n",
       "       [0.5960963 , 0.4039037 ],\n",
       "       [0.5960851 , 0.40391493],\n",
       "       [0.59616274, 0.4038373 ],\n",
       "       [0.5934108 , 0.4065892 ],\n",
       "       [0.59671503, 0.403285  ],\n",
       "       [0.6255371 , 0.37446284],\n",
       "       [0.5943473 , 0.40565267],\n",
       "       [0.5957511 , 0.40424886],\n",
       "       [0.59716266, 0.40283737],\n",
       "       [0.59716475, 0.40283525],\n",
       "       [0.59538287, 0.40461704],\n",
       "       [0.5956379 , 0.40436214],\n",
       "       [0.59717035, 0.4028297 ],\n",
       "       [0.59418637, 0.40581357],\n",
       "       [0.60397667, 0.39602327],\n",
       "       [0.6243422 , 0.37565786],\n",
       "       [0.63971573, 0.36028433],\n",
       "       [0.6183078 , 0.38169217],\n",
       "       [0.5957278 , 0.40427223],\n",
       "       [0.61832523, 0.3816748 ],\n",
       "       [0.5968165 , 0.40318352],\n",
       "       [0.60000443, 0.39999557],\n",
       "       [0.59930605, 0.40069392],\n",
       "       [0.5954215 , 0.40457845],\n",
       "       [0.59509546, 0.40490457],\n",
       "       [0.5357631 , 0.4642369 ],\n",
       "       [0.5950606 , 0.40493944],\n",
       "       [0.59526175, 0.4047383 ],\n",
       "       [0.5965137 , 0.4034863 ],\n",
       "       [0.59417117, 0.40582892],\n",
       "       [0.5611133 , 0.43888664]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(out).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_dct_weights = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('convnorm.0.conv1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.0.conv1.lin.weight',\n",
       "              tensor([[-0.6960, -0.2857, -0.4705,  0.3328],\n",
       "                      [-0.3953,  0.2961, -0.0522, -0.3544],\n",
       "                      [-0.5714,  0.5813,  0.0144, -0.4987],\n",
       "                      [ 0.6627, -0.3085, -0.5909,  0.0024],\n",
       "                      [-0.2920,  0.4495, -0.3203, -0.3361],\n",
       "                      [-0.0359, -0.2881, -0.2071, -0.0669],\n",
       "                      [ 0.1197, -0.6250,  0.6247, -0.5719],\n",
       "                      [ 0.3925,  0.4046,  0.1400, -0.6088]])),\n",
       "             ('convnorm.0.bnr1.module.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('convnorm.0.bnr1.module.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.0.bnr1.module.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.0.bnr1.module.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('convnorm.0.bnr1.module.num_batches_tracked', tensor(0)),\n",
       "             ('convnorm.1.conv1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.1.conv1.lin.weight',\n",
       "              tensor([[-0.1698, -0.0743,  0.4554, -0.3382,  0.0979, -0.3818, -0.4811,  0.0270],\n",
       "                      [ 0.1550, -0.0348, -0.4460, -0.1597,  0.2614, -0.4875,  0.3353, -0.2593],\n",
       "                      [-0.3186, -0.1462,  0.3153, -0.1257,  0.4948,  0.3895,  0.1224,  0.3104],\n",
       "                      [-0.0905, -0.3532, -0.4127,  0.3762, -0.3099,  0.3347, -0.2255, -0.2305],\n",
       "                      [ 0.2362, -0.2927,  0.3225, -0.0613, -0.0532, -0.2213, -0.4005,  0.4785],\n",
       "                      [ 0.0466,  0.4732, -0.4683, -0.0801, -0.2369,  0.2609,  0.0645,  0.4794],\n",
       "                      [-0.2137, -0.1625,  0.3150, -0.3439,  0.2495,  0.4866,  0.3569, -0.4705],\n",
       "                      [ 0.3726, -0.1762, -0.0816,  0.2320, -0.1440, -0.4668, -0.2204, -0.2072],\n",
       "                      [ 0.1169,  0.3487,  0.2741,  0.1753, -0.2999,  0.2500, -0.2031,  0.1751],\n",
       "                      [-0.1264,  0.2657,  0.3911,  0.1213, -0.4621,  0.0956,  0.3537, -0.3343],\n",
       "                      [-0.2507,  0.3817, -0.4977,  0.3503,  0.1531, -0.3153,  0.2335,  0.0093],\n",
       "                      [ 0.3265, -0.0868, -0.0252,  0.0731,  0.0839, -0.0726, -0.2487, -0.3206],\n",
       "                      [-0.3465, -0.4271,  0.2343, -0.0992, -0.1113, -0.2084,  0.1383, -0.1094],\n",
       "                      [ 0.0652,  0.3999, -0.0408,  0.1367,  0.2415,  0.4664,  0.3946,  0.1114],\n",
       "                      [ 0.2146, -0.2183,  0.0053,  0.4261, -0.2233,  0.0869, -0.1315,  0.3261],\n",
       "                      [-0.4486, -0.1985,  0.3964,  0.3318, -0.0365,  0.3796,  0.1633, -0.2208]])),\n",
       "             ('convnorm.1.bnr1.module.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('convnorm.1.bnr1.module.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.1.bnr1.module.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.1.bnr1.module.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('convnorm.1.bnr1.module.num_batches_tracked', tensor(0)),\n",
       "             ('convnorm.2.conv1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.2.conv1.lin.weight',\n",
       "              tensor([[ 0.0612,  0.0450, -0.1881,  0.1268,  0.2012, -0.2804,  0.0031, -0.3061,\n",
       "                        0.0517, -0.2733, -0.2071,  0.2732,  0.3051, -0.0517, -0.2560, -0.3333],\n",
       "                      [-0.0536, -0.2076, -0.1725,  0.1509,  0.0644,  0.2454, -0.1245,  0.1033,\n",
       "                        0.1895, -0.1145,  0.1675, -0.2560,  0.1359, -0.0449,  0.0236, -0.2039],\n",
       "                      [ 0.3395,  0.0215,  0.1417,  0.2841,  0.0220,  0.2199,  0.1775, -0.1933,\n",
       "                        0.2877,  0.0376, -0.2647,  0.1744,  0.0554,  0.1003, -0.3413,  0.0252],\n",
       "                      [-0.0742,  0.2736, -0.2350, -0.3052, -0.1941, -0.0219, -0.3473, -0.1843,\n",
       "                       -0.3360,  0.0185,  0.0452, -0.2221, -0.0182, -0.1683,  0.2484, -0.0834],\n",
       "                      [-0.2675,  0.2742, -0.0285,  0.2289, -0.1031, -0.3416,  0.0331, -0.0923,\n",
       "                       -0.2048,  0.3414,  0.2177, -0.1319,  0.2940,  0.2023, -0.2693, -0.1598],\n",
       "                      [ 0.1966, -0.1637, -0.1899,  0.2273, -0.3374, -0.1792, -0.2309, -0.2136,\n",
       "                       -0.2355, -0.2191,  0.1715, -0.0826,  0.2597,  0.0090,  0.0733,  0.1316],\n",
       "                      [ 0.1969, -0.3502,  0.0889, -0.1289, -0.0999, -0.2405,  0.2859, -0.0912,\n",
       "                       -0.0421, -0.0224,  0.2513,  0.3451,  0.0106, -0.2902,  0.2623,  0.2908],\n",
       "                      [ 0.0625,  0.1213, -0.1024,  0.0299, -0.2423,  0.1465,  0.1608,  0.3299,\n",
       "                       -0.0453, -0.1789,  0.1777,  0.1157, -0.3009,  0.3139,  0.0686, -0.1554],\n",
       "                      [-0.0149,  0.2641,  0.0471, -0.0670, -0.3154, -0.1657,  0.1978, -0.3181,\n",
       "                        0.1860,  0.0124,  0.1481, -0.2768, -0.3182, -0.2743, -0.0937, -0.1390],\n",
       "                      [ 0.2417,  0.2702, -0.0700, -0.0246, -0.0271,  0.2836,  0.1903,  0.1052,\n",
       "                       -0.3069, -0.1674,  0.0205, -0.1869, -0.0645,  0.2508,  0.3231,  0.3449],\n",
       "                      [ 0.1610, -0.1367,  0.1379, -0.2156, -0.2519,  0.3310,  0.3074,  0.2457,\n",
       "                       -0.3039,  0.0397, -0.1082, -0.2561,  0.2075, -0.2809,  0.0451, -0.1437],\n",
       "                      [ 0.1659, -0.0988, -0.2741,  0.0341, -0.1369,  0.1339,  0.0978,  0.2636,\n",
       "                        0.2988,  0.2021,  0.1114, -0.3498, -0.2284,  0.3162,  0.2942, -0.2825],\n",
       "                      [-0.1019, -0.3413,  0.2587,  0.1399, -0.2550,  0.0487,  0.2623, -0.0766,\n",
       "                       -0.3106,  0.1801, -0.2226, -0.1530,  0.0184, -0.1141, -0.0602,  0.1306],\n",
       "                      [ 0.1964, -0.2646,  0.0545,  0.1592, -0.1820, -0.1830, -0.1478, -0.2437,\n",
       "                       -0.2997, -0.3172, -0.1859, -0.2595,  0.1393, -0.3311,  0.1179, -0.2280],\n",
       "                      [ 0.0112,  0.2623, -0.0940,  0.3142, -0.2348,  0.3126, -0.3519,  0.1740,\n",
       "                        0.2137,  0.2717,  0.3445,  0.3531,  0.0338, -0.1979,  0.2880,  0.2078],\n",
       "                      [ 0.3014,  0.3216, -0.0318, -0.1082, -0.0180,  0.3140, -0.0179, -0.0223,\n",
       "                        0.0073, -0.2090, -0.2478, -0.3182,  0.1094, -0.0276, -0.1246, -0.1774],\n",
       "                      [-0.0900,  0.0429, -0.0554, -0.1999,  0.1744, -0.1091,  0.2415,  0.0153,\n",
       "                        0.1471,  0.1536,  0.1197,  0.2260,  0.2396, -0.2353,  0.1959,  0.2370],\n",
       "                      [-0.2142,  0.0966,  0.1904, -0.2686,  0.2671,  0.2964,  0.0439, -0.1276,\n",
       "                        0.2690,  0.0949,  0.2852,  0.1156, -0.3136,  0.0165, -0.0153, -0.0086],\n",
       "                      [ 0.1556, -0.0360,  0.3412,  0.1456,  0.1815, -0.2999, -0.2443,  0.2553,\n",
       "                        0.2548, -0.1879,  0.0380, -0.0338, -0.2866, -0.0439,  0.1657, -0.0819],\n",
       "                      [ 0.2321, -0.1393, -0.3306, -0.0597, -0.0917, -0.1889, -0.0521,  0.3326,\n",
       "                       -0.1224,  0.2192,  0.1674,  0.0262, -0.1769, -0.3066,  0.1843, -0.3490],\n",
       "                      [-0.1658, -0.3378, -0.2386,  0.1688,  0.1883, -0.2862, -0.2708,  0.0537,\n",
       "                       -0.0676, -0.3000, -0.2716,  0.0909,  0.0085, -0.0248,  0.2078, -0.0318],\n",
       "                      [ 0.1125,  0.1785, -0.0979,  0.0845,  0.1990,  0.0687,  0.1934,  0.0715,\n",
       "                        0.2479,  0.2080, -0.0109,  0.2191, -0.0168, -0.0904, -0.2284,  0.2003],\n",
       "                      [-0.2684,  0.1293,  0.3047,  0.2993,  0.1704,  0.0975, -0.0423,  0.3495,\n",
       "                       -0.1224, -0.0602, -0.0917, -0.1182,  0.2432, -0.2199,  0.2458, -0.2640],\n",
       "                      [ 0.1790,  0.3087, -0.3309, -0.2317,  0.0196,  0.2954, -0.1904,  0.1682,\n",
       "                        0.3027,  0.2055, -0.0944,  0.1680, -0.2890, -0.2831,  0.0128,  0.2550],\n",
       "                      [ 0.3419,  0.2316,  0.1744,  0.0952,  0.1502,  0.0605,  0.0098,  0.0026,\n",
       "                       -0.2135,  0.3004, -0.1205, -0.0960, -0.2020, -0.3205, -0.1662,  0.2486],\n",
       "                      [-0.3514,  0.0331,  0.1916,  0.1067,  0.0631, -0.2974, -0.0918,  0.0960,\n",
       "                        0.2256,  0.0057, -0.1842, -0.0227, -0.1316,  0.0959, -0.2811, -0.0437],\n",
       "                      [-0.0987, -0.3297, -0.0792,  0.1624, -0.0819,  0.3009, -0.2973, -0.2150,\n",
       "                        0.2419,  0.1040,  0.0292, -0.2749,  0.0506, -0.3527,  0.3243,  0.2747],\n",
       "                      [-0.1821, -0.2694, -0.0637, -0.0526,  0.3007,  0.2278, -0.0706, -0.2513,\n",
       "                        0.2803, -0.0607, -0.3417,  0.0387,  0.2691,  0.1707, -0.3076,  0.1768],\n",
       "                      [ 0.2691,  0.0514,  0.2641, -0.0031,  0.3009,  0.1642, -0.2559,  0.3457,\n",
       "                       -0.0520,  0.2138, -0.3413,  0.1905,  0.2658,  0.1887, -0.2071, -0.0093],\n",
       "                      [-0.2970,  0.1242, -0.3135, -0.2611, -0.2936, -0.0334, -0.3393,  0.1440,\n",
       "                       -0.1715,  0.2256,  0.1472,  0.0199, -0.1438,  0.0051, -0.0950, -0.0163],\n",
       "                      [ 0.1568,  0.1731, -0.2388, -0.1397,  0.1827,  0.1345, -0.1228,  0.1682,\n",
       "                       -0.2498,  0.1878, -0.2965,  0.2472, -0.1643,  0.1391,  0.0103,  0.1103],\n",
       "                      [-0.0518,  0.2065, -0.1053,  0.0517, -0.1245, -0.0205, -0.2160,  0.0679,\n",
       "                       -0.0322, -0.1600, -0.1241, -0.0132, -0.1785, -0.0252,  0.0287, -0.3469]])),\n",
       "             ('convnorm.2.bnr1.module.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('convnorm.2.bnr1.module.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.2.bnr1.module.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.2.bnr1.module.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('convnorm.2.bnr1.module.num_batches_tracked', tensor(0)),\n",
       "             ('convnorm.3.conv1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.3.conv1.lin.weight',\n",
       "              tensor([[-0.2039, -0.1684,  0.0674,  ...,  0.0752, -0.1402,  0.2367],\n",
       "                      [ 0.0659, -0.2186,  0.1869,  ..., -0.1899, -0.1494,  0.0892],\n",
       "                      [ 0.0807,  0.1026, -0.1026,  ..., -0.0755,  0.1215, -0.1135],\n",
       "                      ...,\n",
       "                      [ 0.0237,  0.1815, -0.0051,  ..., -0.0373,  0.0951,  0.1114],\n",
       "                      [-0.1518,  0.0247, -0.1701,  ...,  0.0854,  0.0208, -0.1054],\n",
       "                      [-0.1476, -0.1538,  0.0596,  ..., -0.1344,  0.0912,  0.2251]])),\n",
       "             ('convnorm.3.bnr1.module.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('convnorm.3.bnr1.module.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.3.bnr1.module.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('convnorm.3.bnr1.module.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('convnorm.3.bnr1.module.num_batches_tracked', tensor(0)),\n",
       "             ('linears.0.fc1.weight',\n",
       "              tensor([[ 0.0437,  0.4111,  0.1127, -0.4696],\n",
       "                      [-0.0552,  0.3693,  0.1399, -0.2522],\n",
       "                      [-0.4838, -0.4220, -0.4755, -0.4564],\n",
       "                      [-0.4027, -0.4836, -0.0972,  0.4774]])),\n",
       "             ('linears.0.fc1.bias', tensor([0.0473, 0.4887, 0.2098, 0.3671])),\n",
       "             ('linears.0.fc2.weight',\n",
       "              tensor([[-0.1800, -0.3351,  0.3980,  0.2620],\n",
       "                      [-0.2094, -0.0293, -0.4679,  0.3208]])),\n",
       "             ('linears.0.fc2.bias', tensor([-0.4474,  0.0901])),\n",
       "             ('linears.1.fc1.weight',\n",
       "              tensor([[ 0.1006, -0.2345,  0.1715, -0.0568,  0.2121, -0.1391,  0.0637, -0.3283],\n",
       "                      [-0.0742,  0.0450, -0.2119, -0.3346, -0.1171,  0.0569, -0.0087, -0.0768],\n",
       "                      [-0.0612, -0.1336,  0.2224,  0.0455,  0.1639, -0.1359, -0.1014,  0.1472],\n",
       "                      [-0.2816, -0.3119,  0.3535,  0.3002, -0.2493, -0.2308, -0.0119,  0.2675],\n",
       "                      [-0.2075,  0.2919,  0.1807,  0.0338, -0.1415, -0.1645,  0.0167, -0.2725],\n",
       "                      [-0.1654,  0.1772,  0.2654,  0.1866,  0.2681, -0.0429, -0.0891,  0.2749],\n",
       "                      [-0.2697,  0.0686,  0.0642, -0.0207,  0.1826, -0.0050,  0.2187,  0.0340],\n",
       "                      [ 0.1488,  0.3275, -0.1961, -0.1267,  0.0336,  0.2858,  0.3188, -0.2968]])),\n",
       "             ('linears.1.fc1.bias',\n",
       "              tensor([ 0.2238, -0.2394,  0.0367, -0.1180, -0.0886, -0.1539, -0.2284, -0.3374])),\n",
       "             ('linears.1.fc2.weight',\n",
       "              tensor([[ 0.3387,  0.1384, -0.1042,  0.0166,  0.0474,  0.1954, -0.1946, -0.0777],\n",
       "                      [-0.3440, -0.1982,  0.1394, -0.0887, -0.2287,  0.3090,  0.0559, -0.2896],\n",
       "                      [ 0.1610, -0.0519, -0.2809,  0.3349,  0.2689,  0.1262, -0.0126,  0.2760],\n",
       "                      [ 0.2084, -0.2875, -0.1183,  0.0764,  0.2903, -0.1026, -0.1887, -0.3476]])),\n",
       "             ('linears.1.fc2.bias',\n",
       "              tensor([-0.0965, -0.2530, -0.1633,  0.2095])),\n",
       "             ('linears.2.fc1.weight',\n",
       "              tensor([[ 4.8972e-02, -3.3898e-02,  1.5420e-01,  1.6166e-01,  1.1138e-01,\n",
       "                        5.7530e-02,  1.0359e-01, -1.4590e-01, -1.5116e-01, -4.4370e-02,\n",
       "                        2.4814e-02,  7.9825e-02,  2.2442e-01, -6.1049e-02, -1.3124e-01,\n",
       "                       -1.7880e-01],\n",
       "                      [-1.7980e-01,  9.5020e-02,  1.5825e-01, -4.9835e-02,  2.3300e-01,\n",
       "                       -2.1599e-01, -1.9592e-01,  2.0876e-01,  1.0018e-01,  1.3146e-01,\n",
       "                       -1.7029e-01,  1.3347e-01,  8.6264e-02, -1.4168e-01, -2.8957e-03,\n",
       "                       -5.4339e-03],\n",
       "                      [-2.0743e-01, -2.4500e-01,  5.2812e-02,  1.3896e-02,  6.0383e-02,\n",
       "                       -1.2171e-01, -1.0204e-01, -1.2583e-04, -1.3634e-01,  2.1136e-01,\n",
       "                        1.2126e-01,  2.4935e-01, -2.2297e-01,  7.6516e-02, -5.4423e-02,\n",
       "                        2.0208e-02],\n",
       "                      [-1.6767e-01,  1.1291e-01,  4.4569e-02,  7.6134e-02, -3.7148e-02,\n",
       "                        1.0873e-01,  1.8148e-01, -2.2063e-01,  1.6841e-01, -4.6731e-02,\n",
       "                        1.0222e-01, -4.4877e-02,  9.7701e-02,  1.5084e-01, -8.8105e-02,\n",
       "                       -9.8844e-02],\n",
       "                      [ 3.7226e-02, -8.5865e-02,  1.7680e-01, -1.8713e-02,  2.4948e-01,\n",
       "                        2.7928e-02,  9.2117e-02, -2.1317e-01, -1.8706e-01,  1.4217e-01,\n",
       "                       -4.8225e-02, -2.4832e-01, -1.9012e-01, -6.3136e-02,  1.7915e-02,\n",
       "                       -3.2055e-03],\n",
       "                      [-2.1762e-01,  8.3837e-02, -1.1291e-01,  1.2666e-01,  1.1635e-01,\n",
       "                        1.5511e-01, -1.0852e-01, -1.4078e-01, -1.2856e-01, -1.5989e-01,\n",
       "                       -2.3066e-01, -1.4168e-01,  1.1662e-01, -1.3214e-01,  1.7250e-02,\n",
       "                        4.7170e-02],\n",
       "                      [-6.6609e-02,  1.9907e-01,  1.1457e-01,  1.9284e-01, -1.1006e-01,\n",
       "                       -9.7956e-02, -2.4333e-01, -2.2889e-01,  9.4622e-02, -1.7068e-01,\n",
       "                       -2.7798e-02, -9.3412e-03,  2.4285e-01, -1.4739e-01, -7.9884e-02,\n",
       "                        1.0941e-01],\n",
       "                      [-1.1455e-01, -7.6635e-02, -8.7838e-03, -5.4447e-02,  1.0135e-01,\n",
       "                        1.1099e-01, -2.2381e-01,  1.6253e-01,  2.6438e-02, -1.4005e-02,\n",
       "                       -1.0303e-02,  4.5604e-02,  1.0416e-01, -1.9591e-01,  1.6249e-01,\n",
       "                       -3.0563e-02],\n",
       "                      [-1.7454e-01, -4.0462e-02,  2.0111e-01,  1.7508e-01,  1.1539e-01,\n",
       "                       -1.1856e-01,  1.8820e-01, -1.3007e-01,  1.2158e-01,  5.4961e-02,\n",
       "                        1.8963e-01,  2.8771e-02,  8.5356e-02,  1.9473e-01,  1.4743e-01,\n",
       "                       -8.3357e-03],\n",
       "                      [ 2.4819e-01,  2.7226e-02, -1.7948e-01,  2.4628e-01,  2.3783e-02,\n",
       "                        1.4056e-01, -2.2978e-01,  1.4143e-01, -1.6814e-01, -1.3268e-01,\n",
       "                        3.1149e-02,  2.1938e-01, -2.1247e-01, -1.0082e-01,  1.5813e-01,\n",
       "                        1.6438e-01],\n",
       "                      [-2.3464e-01,  1.4841e-02, -5.6061e-02,  1.2516e-01, -2.4065e-01,\n",
       "                       -1.4243e-01,  2.3524e-02, -1.4237e-01, -2.4591e-01, -1.7162e-01,\n",
       "                        4.1735e-02,  1.0327e-01,  8.8031e-02,  1.9154e-01, -1.9669e-01,\n",
       "                       -1.8649e-01],\n",
       "                      [-2.4248e-01,  9.1779e-02, -8.9048e-02,  4.2002e-03,  1.5516e-01,\n",
       "                       -1.3878e-01, -1.7256e-03, -1.5525e-01,  2.7382e-02, -9.0040e-02,\n",
       "                       -5.2539e-02, -9.1908e-02,  2.3638e-01,  2.3063e-01, -6.9350e-02,\n",
       "                       -2.3143e-01],\n",
       "                      [ 1.5512e-03,  7.1332e-02,  2.2616e-01,  2.2316e-01,  6.2801e-02,\n",
       "                        2.0782e-01, -2.1748e-02,  5.4706e-02,  1.5474e-01,  2.4865e-01,\n",
       "                        1.8257e-01,  3.0153e-02, -1.1486e-02,  1.2096e-01,  2.4321e-01,\n",
       "                       -1.8959e-01],\n",
       "                      [-2.1663e-02, -1.1935e-01,  1.4611e-01, -2.1392e-01,  1.5626e-01,\n",
       "                       -8.7978e-02,  1.8809e-01, -1.4100e-01, -2.2013e-01, -1.9922e-01,\n",
       "                        1.9031e-01, -2.2948e-01, -1.8237e-01,  2.4276e-01, -1.7418e-01,\n",
       "                        1.6192e-01],\n",
       "                      [ 1.3553e-02, -1.2228e-01, -3.6287e-02, -1.4611e-01, -2.0390e-01,\n",
       "                       -1.4702e-01, -2.3379e-03,  8.9448e-02,  1.3258e-01,  2.3886e-01,\n",
       "                        6.2112e-02,  5.1826e-02, -1.7776e-01,  4.9048e-02,  1.3250e-01,\n",
       "                        1.2890e-02],\n",
       "                      [ 4.3774e-02, -2.4621e-02,  4.7741e-02,  2.2795e-01, -6.2618e-02,\n",
       "                        1.1033e-02,  2.0638e-01,  1.9362e-01, -9.2040e-02,  2.0866e-01,\n",
       "                       -1.7114e-01, -2.4018e-01,  1.7480e-01,  8.6000e-02, -2.3041e-01,\n",
       "                        8.4211e-02]])),\n",
       "             ('linears.2.fc1.bias',\n",
       "              tensor([-0.2414,  0.2001, -0.0984, -0.1217,  0.0262,  0.0228,  0.2426, -0.0896,\n",
       "                      -0.2261, -0.1012, -0.0555, -0.1637, -0.1456, -0.0787,  0.1037, -0.0472])),\n",
       "             ('linears.2.fc2.weight',\n",
       "              tensor([[ 0.0724,  0.2310,  0.2179,  0.0144,  0.1103, -0.0167,  0.1290, -0.0548,\n",
       "                        0.1378,  0.1912, -0.1864,  0.1221,  0.1882, -0.1517, -0.0359, -0.0536],\n",
       "                      [ 0.0416, -0.2217,  0.2239, -0.0675, -0.1222,  0.1213,  0.2308,  0.1882,\n",
       "                        0.1124, -0.1313, -0.1454, -0.1010, -0.2015,  0.0624,  0.0316, -0.0016],\n",
       "                      [ 0.2305, -0.1602,  0.0298, -0.2176,  0.1360, -0.2110, -0.2253, -0.1587,\n",
       "                       -0.1645,  0.2211, -0.2180,  0.2255, -0.0272,  0.1317, -0.2378, -0.0088],\n",
       "                      [ 0.0607,  0.0744,  0.1655,  0.0004,  0.1426, -0.2018, -0.1018, -0.2066,\n",
       "                        0.1339, -0.2085, -0.2280, -0.0358,  0.0502, -0.0925, -0.1861,  0.0936],\n",
       "                      [ 0.0606, -0.2268, -0.2218,  0.2007,  0.0758,  0.2496,  0.1236,  0.1832,\n",
       "                        0.1634,  0.0993, -0.0655,  0.1391,  0.0726, -0.0038, -0.0451,  0.0568],\n",
       "                      [ 0.2411,  0.0349,  0.1199, -0.1701, -0.0460,  0.0814, -0.0431, -0.1543,\n",
       "                       -0.2489, -0.0116,  0.1453,  0.0794, -0.0412, -0.0135, -0.2231,  0.0630],\n",
       "                      [-0.2385, -0.0831, -0.1773,  0.0882, -0.2010,  0.1130, -0.0736, -0.0403,\n",
       "                       -0.0888,  0.1453,  0.1723, -0.1413, -0.1876,  0.1307, -0.1429, -0.0363],\n",
       "                      [ 0.2459, -0.0861,  0.1045,  0.1597,  0.0582, -0.1834,  0.2135, -0.2102,\n",
       "                        0.1752, -0.1862, -0.1250, -0.0314,  0.1784,  0.1883,  0.2360, -0.1459]])),\n",
       "             ('linears.2.fc2.bias',\n",
       "              tensor([ 0.1068,  0.1054, -0.0858,  0.1287, -0.0833, -0.2014, -0.1684, -0.2094])),\n",
       "             ('linears.3.fc1.weight',\n",
       "              tensor([[-0.1307, -0.1347,  0.0206,  ..., -0.0539,  0.1452, -0.0254],\n",
       "                      [ 0.0633,  0.0011,  0.0869,  ..., -0.1261,  0.0978,  0.0170],\n",
       "                      [ 0.1180,  0.0807, -0.0794,  ..., -0.1397, -0.0470, -0.0985],\n",
       "                      ...,\n",
       "                      [-0.0161,  0.0264, -0.1646,  ...,  0.1680, -0.0433, -0.0941],\n",
       "                      [-0.1062,  0.0232, -0.0202,  ..., -0.1038,  0.0259,  0.1186],\n",
       "                      [-0.0094,  0.0239, -0.0231,  ..., -0.1548,  0.1583,  0.0415]])),\n",
       "             ('linears.3.fc1.bias',\n",
       "              tensor([-0.0551,  0.1131,  0.0589,  0.1678, -0.1433, -0.1512,  0.1079,  0.0243,\n",
       "                       0.0778, -0.0749,  0.0331, -0.1519, -0.0194,  0.1537,  0.0002,  0.1180,\n",
       "                       0.0900, -0.0393,  0.0697,  0.0112, -0.1281,  0.1556,  0.0921,  0.0759,\n",
       "                      -0.0258,  0.1230,  0.1268, -0.0548, -0.0549,  0.1276, -0.0418,  0.1264])),\n",
       "             ('linears.3.fc2.weight',\n",
       "              tensor([[-0.1421, -0.1444,  0.1012, -0.1105,  0.0244,  0.0113,  0.1066,  0.1357,\n",
       "                        0.0618, -0.1406, -0.1486,  0.0785, -0.1376,  0.0514, -0.0476,  0.0921,\n",
       "                       -0.1727,  0.0938,  0.0492, -0.0933, -0.0550,  0.1048, -0.1581, -0.1711,\n",
       "                       -0.0452,  0.1103,  0.1459,  0.0063, -0.1317, -0.0839, -0.0350,  0.1262],\n",
       "                      [ 0.0641,  0.1672,  0.0858, -0.1296, -0.0207, -0.0766, -0.1241,  0.0661,\n",
       "                        0.1747, -0.1297, -0.0821,  0.1459,  0.0630, -0.0820,  0.0781,  0.1192,\n",
       "                       -0.1638,  0.0193,  0.0893, -0.0078,  0.0444, -0.1058, -0.1594,  0.1565,\n",
       "                       -0.1090, -0.0620,  0.0573,  0.0508,  0.0013,  0.1717,  0.0329, -0.0063],\n",
       "                      [ 0.1616, -0.0419, -0.0461, -0.0449,  0.0064,  0.0444,  0.0093, -0.1011,\n",
       "                        0.0587,  0.0711, -0.0848, -0.0977,  0.1575, -0.1105, -0.0885, -0.1483,\n",
       "                        0.1081, -0.0209,  0.0219,  0.1734, -0.1418, -0.0279,  0.1534, -0.0911,\n",
       "                       -0.0649,  0.0253, -0.0031, -0.0326,  0.0267, -0.1718, -0.0813, -0.0281],\n",
       "                      [ 0.0496, -0.0848, -0.1520, -0.0746, -0.0161,  0.0401, -0.0985, -0.1100,\n",
       "                        0.0522,  0.1418, -0.0484, -0.0099, -0.1745, -0.0955, -0.0173,  0.0561,\n",
       "                        0.0972,  0.1499, -0.1344,  0.0998, -0.0110, -0.1038, -0.0979,  0.1186,\n",
       "                       -0.1393, -0.0382,  0.0307,  0.1724,  0.0132,  0.1180, -0.1519,  0.1251],\n",
       "                      [ 0.1276,  0.0522,  0.0307, -0.1199, -0.0471,  0.0534,  0.0694,  0.1460,\n",
       "                       -0.1154, -0.0258, -0.1173, -0.0897,  0.1704,  0.0893, -0.0834, -0.1466,\n",
       "                       -0.0901,  0.0951, -0.0654, -0.1320, -0.0691, -0.0969,  0.1119,  0.0935,\n",
       "                        0.0848,  0.1194,  0.1292, -0.0712,  0.0352,  0.1457, -0.1429, -0.0272],\n",
       "                      [-0.0579, -0.0525,  0.0772, -0.0475,  0.1718,  0.0203,  0.0160, -0.0861,\n",
       "                        0.1735,  0.1624,  0.1046,  0.0636,  0.0079, -0.1125,  0.0911,  0.0916,\n",
       "                       -0.1116,  0.0219, -0.0829, -0.1282, -0.0264,  0.0202,  0.1055, -0.0452,\n",
       "                        0.0903, -0.1486, -0.0618,  0.1380, -0.1082, -0.0636,  0.1610, -0.0386],\n",
       "                      [-0.1539, -0.1509, -0.0015, -0.0175, -0.1654, -0.1740,  0.0991,  0.0442,\n",
       "                       -0.1053,  0.0674, -0.0619, -0.1002,  0.0268,  0.0043,  0.1414,  0.1303,\n",
       "                       -0.1505, -0.0778,  0.1481, -0.0151, -0.1515, -0.1436,  0.1656,  0.1193,\n",
       "                       -0.1163,  0.0351, -0.0314,  0.0836, -0.1008, -0.1709,  0.1524,  0.0005],\n",
       "                      [-0.0749,  0.0931, -0.0789, -0.0084, -0.0328, -0.1756, -0.1711,  0.0200,\n",
       "                       -0.1058, -0.0120, -0.1633,  0.0079, -0.0763,  0.0750, -0.0974, -0.1190,\n",
       "                        0.1680, -0.1305,  0.1127, -0.0066,  0.0746,  0.0075, -0.1396, -0.1509,\n",
       "                       -0.0087, -0.0172, -0.1618, -0.0043, -0.0813, -0.1465,  0.0333, -0.1017],\n",
       "                      [ 0.1055,  0.1561,  0.0233,  0.0403, -0.1688,  0.1725,  0.1184,  0.1535,\n",
       "                        0.1512, -0.1095, -0.0182,  0.0379,  0.0208,  0.0541, -0.0276, -0.1249,\n",
       "                       -0.0489, -0.0359,  0.1696, -0.1481,  0.0474, -0.0347,  0.1275,  0.0344,\n",
       "                        0.1412, -0.1445, -0.1008, -0.1292,  0.0561,  0.0358,  0.0419, -0.1446],\n",
       "                      [ 0.1454, -0.0331, -0.0274, -0.0256,  0.0564, -0.0170,  0.1538,  0.1382,\n",
       "                       -0.0112,  0.0770,  0.1253,  0.0334, -0.1718,  0.0236,  0.1235, -0.1200,\n",
       "                       -0.1638,  0.0400, -0.0184, -0.0244, -0.0849, -0.1389, -0.0438, -0.0591,\n",
       "                       -0.0124, -0.0765, -0.1451, -0.0225, -0.0422, -0.1203,  0.0155, -0.0567],\n",
       "                      [ 0.0983,  0.0135,  0.1509,  0.1393, -0.1678, -0.0498, -0.1439,  0.0473,\n",
       "                        0.0359,  0.1452,  0.1156, -0.1505, -0.1676, -0.0566,  0.0455, -0.1028,\n",
       "                       -0.1578,  0.1765, -0.1614, -0.1652,  0.1372, -0.1626,  0.1172, -0.1158,\n",
       "                        0.1333,  0.0172, -0.1146, -0.0082,  0.1617, -0.0264,  0.0420, -0.0157],\n",
       "                      [ 0.1512,  0.1116, -0.0452, -0.0085,  0.1748,  0.1336,  0.0904, -0.1090,\n",
       "                       -0.0378, -0.1211,  0.0668,  0.0627, -0.0741, -0.0967, -0.0059,  0.1166,\n",
       "                       -0.1233,  0.0018, -0.1183, -0.1508,  0.0463,  0.0172, -0.1184, -0.0123,\n",
       "                        0.0198,  0.0827, -0.1698,  0.1372,  0.1680,  0.1160, -0.1460, -0.0491],\n",
       "                      [ 0.0396,  0.1306,  0.0483,  0.0043,  0.0703,  0.0260,  0.0448, -0.1659,\n",
       "                        0.1676,  0.1505,  0.0123, -0.0314,  0.0741, -0.0156,  0.0286, -0.0671,\n",
       "                        0.1105,  0.1649, -0.1302,  0.1076,  0.1567, -0.0508,  0.0294, -0.1656,\n",
       "                       -0.1531,  0.1247,  0.0128,  0.0314,  0.0516, -0.1118, -0.0624,  0.1657],\n",
       "                      [ 0.0692,  0.0929, -0.0117, -0.1445, -0.1686,  0.1125, -0.1104,  0.1467,\n",
       "                        0.1438, -0.0109,  0.1492,  0.0937, -0.0404, -0.0073,  0.0335, -0.1498,\n",
       "                        0.0134,  0.1320,  0.0740,  0.0098,  0.1755,  0.0536,  0.0957,  0.1172,\n",
       "                       -0.1612,  0.0203, -0.0540,  0.0231,  0.0276, -0.1248,  0.0673, -0.0188],\n",
       "                      [-0.0597,  0.0139, -0.1091, -0.0531,  0.1536, -0.0031, -0.0441,  0.1011,\n",
       "                        0.0119, -0.0418, -0.1672, -0.0654, -0.1408, -0.1520, -0.1429,  0.0862,\n",
       "                       -0.1053,  0.0006, -0.0597,  0.1603, -0.1024,  0.0087, -0.1388,  0.1675,\n",
       "                       -0.1313, -0.0580,  0.0262, -0.0682,  0.0265, -0.0302,  0.0248, -0.0901],\n",
       "                      [ 0.1023, -0.1531,  0.1177,  0.0679,  0.0676,  0.1231, -0.0844,  0.0249,\n",
       "                       -0.0735,  0.0300,  0.0488, -0.0478,  0.0829, -0.0468,  0.1426, -0.0057,\n",
       "                        0.1242, -0.1150,  0.1178,  0.1620, -0.0540, -0.0191,  0.1005, -0.0450,\n",
       "                       -0.1130, -0.0840,  0.0720,  0.0549,  0.1569, -0.1372, -0.0419,  0.1466]])),\n",
       "             ('linears.3.fc2.bias',\n",
       "              tensor([ 0.0082, -0.1753,  0.0171, -0.0258,  0.0439,  0.0152,  0.0208, -0.0808,\n",
       "                       0.0970,  0.0282, -0.1357,  0.1525, -0.1071, -0.0269, -0.0371,  0.0870])),\n",
       "             ('linears.4.fc1.weight',\n",
       "              tensor([[ 0.1055, -0.0378,  0.0398,  ..., -0.1034,  0.0765,  0.0709],\n",
       "                      [-0.0977, -0.0979, -0.0708,  ...,  0.1068,  0.0355, -0.0455],\n",
       "                      [-0.0514, -0.0725, -0.1181,  ..., -0.0143, -0.0907,  0.1010],\n",
       "                      ...,\n",
       "                      [-0.1148, -0.0372, -0.0507,  ..., -0.0904, -0.0011, -0.0643],\n",
       "                      [ 0.0297, -0.0947, -0.0587,  ..., -0.1016,  0.1078, -0.0500],\n",
       "                      [ 0.0524,  0.0090, -0.0549,  ...,  0.0359, -0.0917, -0.0695]])),\n",
       "             ('linears.4.fc1.bias',\n",
       "              tensor([ 0.0151, -0.0645, -0.0673, -0.0530, -0.0223, -0.0172,  0.0871, -0.0061,\n",
       "                       0.0266, -0.0310,  0.0058, -0.0895, -0.0789, -0.0971, -0.0978,  0.1017,\n",
       "                       0.0996,  0.0519, -0.1157,  0.0272,  0.0983, -0.0259, -0.0243, -0.0231,\n",
       "                       0.0868,  0.0944, -0.0131,  0.0800,  0.0259, -0.0457,  0.0263,  0.0835,\n",
       "                       0.0894,  0.0905, -0.0363, -0.0020, -0.0491, -0.0861, -0.0928,  0.0376,\n",
       "                       0.1247, -0.0013, -0.1024, -0.0660,  0.0776, -0.0513,  0.0615,  0.0298,\n",
       "                      -0.0252, -0.1016, -0.0143, -0.0548,  0.0762, -0.0088, -0.0609,  0.0374,\n",
       "                       0.0405, -0.1147,  0.1195,  0.0446, -0.0561, -0.0437,  0.0035,  0.0424])),\n",
       "             ('linears.4.fc2.weight',\n",
       "              tensor([[-0.1112, -0.0142, -0.0897,  ..., -0.0741, -0.0722,  0.1152],\n",
       "                      [ 0.0843, -0.0980, -0.1238,  ..., -0.0470,  0.0037, -0.0210],\n",
       "                      [-0.1125, -0.0744,  0.1124,  ...,  0.0235,  0.0763,  0.1158],\n",
       "                      ...,\n",
       "                      [ 0.0805,  0.0193, -0.0746,  ...,  0.0714, -0.0738, -0.1062],\n",
       "                      [-0.0664,  0.0301,  0.1246,  ...,  0.0820,  0.0062, -0.0337],\n",
       "                      [ 0.0352,  0.0543,  0.0247,  ...,  0.0908, -0.1014, -0.0044]])),\n",
       "             ('linears.4.fc2.bias',\n",
       "              tensor([ 0.1132,  0.0823,  0.0127,  0.1098, -0.0774, -0.0977,  0.1246,  0.0064,\n",
       "                      -0.0790,  0.0984, -0.0007,  0.0302,  0.0610, -0.0409, -0.0658, -0.1060,\n",
       "                       0.0824,  0.0472,  0.0910, -0.0559,  0.0226, -0.0210, -0.1137,  0.0771,\n",
       "                      -0.0713, -0.1241,  0.0387,  0.0389,  0.0865, -0.0854,  0.0968, -0.0357]))])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_dct_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_weights = torch.load(saved_weights, map_location=torch.device(device))['state_dict']\n",
    "\n",
    "load_status = model.load_state_dict(dct_weights, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights loaded:  _IncompatibleKeys(missing_keys=[], unexpected_keys=['convnorm.4.conv1.bias', 'convnorm.4.conv1.lin.weight', 'convnorm.4.bnr1.module.weight', 'convnorm.4.bnr1.module.bias', 'convnorm.4.bnr1.module.running_mean', 'convnorm.4.bnr1.module.running_var', 'convnorm.4.bnr1.module.num_batches_tracked', 'convnorm.5.conv1.bias', 'convnorm.5.conv1.lin.weight', 'convnorm.5.bnr1.module.weight', 'convnorm.5.bnr1.module.bias', 'convnorm.5.bnr1.module.running_mean', 'convnorm.5.bnr1.module.running_var', 'convnorm.5.bnr1.module.num_batches_tracked', 'convnorm.6.conv1.bias', 'convnorm.6.conv1.lin.weight', 'convnorm.6.bnr1.module.weight', 'convnorm.6.bnr1.module.bias', 'convnorm.6.bnr1.module.running_mean', 'convnorm.6.bnr1.module.running_var', 'convnorm.6.bnr1.module.num_batches_tracked', 'convnorm.7.conv1.bias', 'convnorm.7.conv1.lin.weight', 'convnorm.7.bnr1.module.weight', 'convnorm.7.bnr1.module.bias', 'convnorm.7.bnr1.module.running_mean', 'convnorm.7.bnr1.module.running_var', 'convnorm.7.bnr1.module.num_batches_tracked', 'linears.5.fc1.weight', 'linears.5.fc1.bias', 'linears.5.fc2.weight', 'linears.5.fc2.bias', 'linears.6.fc1.weight', 'linears.6.fc1.bias', 'linears.6.fc2.weight', 'linears.6.fc2.bias', 'linears.7.fc1.weight', 'linears.7.fc1.bias', 'linears.7.fc2.weight', 'linears.7.fc2.bias', 'linears.8.fc1.weight', 'linears.8.fc1.bias', 'linears.8.fc2.weight', 'linears.8.fc2.bias'])\n"
     ]
    }
   ],
   "source": [
    "print('Weights loaded: ', load_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['convnorm.4.conv1.bias', 'convnorm.4.conv1.lin.weight', 'convnorm.4.bnr1.module.weight', 'convnorm.4.bnr1.module.bias', 'convnorm.4.bnr1.module.running_mean', 'convnorm.4.bnr1.module.running_var', 'convnorm.4.bnr1.module.num_batches_tracked', 'convnorm.5.conv1.bias', 'convnorm.5.conv1.lin.weight', 'convnorm.5.bnr1.module.weight', 'convnorm.5.bnr1.module.bias', 'convnorm.5.bnr1.module.running_mean', 'convnorm.5.bnr1.module.running_var', 'convnorm.5.bnr1.module.num_batches_tracked', 'convnorm.6.conv1.bias', 'convnorm.6.conv1.lin.weight', 'convnorm.6.bnr1.module.weight', 'convnorm.6.bnr1.module.bias', 'convnorm.6.bnr1.module.running_mean', 'convnorm.6.bnr1.module.running_var', 'convnorm.6.bnr1.module.num_batches_tracked', 'convnorm.7.conv1.bias', 'convnorm.7.conv1.lin.weight', 'convnorm.7.bnr1.module.weight', 'convnorm.7.bnr1.module.bias', 'convnorm.7.bnr1.module.running_mean', 'convnorm.7.bnr1.module.running_var', 'convnorm.7.bnr1.module.num_batches_tracked', 'linears.5.fc1.weight', 'linears.5.fc1.bias', 'linears.5.fc2.weight', 'linears.5.fc2.bias', 'linears.6.fc1.weight', 'linears.6.fc1.bias', 'linears.6.fc2.weight', 'linears.6.fc2.bias', 'linears.7.fc1.weight', 'linears.7.fc1.bias', 'linears.7.fc2.weight', 'linears.7.fc2.bias', 'linears.8.fc1.weight', 'linears.8.fc1.bias', 'linears.8.fc2.weight', 'linears.8.fc2.bias'])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('convnorm.0.conv1.bias',\n",
       "              tensor([ 6.9866e-09, -1.1729e-09, -8.5680e-10, -7.1503e-10, -2.7893e-10,\n",
       "                      -8.8031e-09, -1.6517e-09, -2.8132e-10])),\n",
       "             ('convnorm.0.conv1.lin.weight',\n",
       "              tensor([[ 0.0670,  0.5964, -0.3633, -0.2739],\n",
       "                      [-0.3799,  0.2774,  0.0701, -0.4766],\n",
       "                      [-0.3559,  0.1498, -0.6680, -0.6490],\n",
       "                      [-0.1537, -0.2258,  0.2669,  0.3799],\n",
       "                      [ 0.5692, -0.5313,  0.4963, -0.1242],\n",
       "                      [-0.5078,  0.3688,  0.3382, -0.6365],\n",
       "                      [ 0.5977,  0.4232,  0.1251, -0.5059],\n",
       "                      [-0.5510, -0.1620, -0.2563,  0.6564]])),\n",
       "             ('convnorm.0.bnr1.module.weight',\n",
       "              tensor([0.9998, 1.0000, 1.0001, 1.0000, 1.0000, 1.0001, 1.0001, 1.0000])),\n",
       "             ('convnorm.0.bnr1.module.bias',\n",
       "              tensor([ 7.8156e-05, -9.0461e-05,  6.4226e-05,  5.9170e-05,  1.9051e-05,\n",
       "                       7.1587e-05,  3.6490e-05,  2.6887e-05])),\n",
       "             ('convnorm.0.bnr1.module.running_mean',\n",
       "              tensor([-0.6168, -0.3954, -1.2781,  0.6269,  0.3602, -0.2911, -0.3683,  0.3881])),\n",
       "             ('convnorm.0.bnr1.module.running_var',\n",
       "              tensor([0.0050, 0.0020, 0.0212, 0.0051, 0.0017, 0.0011, 0.0018, 0.0020])),\n",
       "             ('convnorm.0.bnr1.module.num_batches_tracked', tensor(183549)),\n",
       "             ('convnorm.1.conv1.bias',\n",
       "              tensor([ 2.2730e-11, -3.7489e-11,  4.0986e-12, -2.2538e-11, -2.2058e-11,\n",
       "                      -5.1311e-13,  4.8935e-12,  1.0230e-11, -2.0448e-11,  1.3014e-11,\n",
       "                       4.1342e-11,  1.0101e-14,  1.4913e-11,  8.3602e-12,  2.5575e-11,\n",
       "                       7.1481e-11])),\n",
       "             ('convnorm.1.conv1.lin.weight',\n",
       "              tensor([[-0.3359, -0.2258,  0.4255,  0.4026,  0.1510,  0.2729,  0.3609,  0.4514],\n",
       "                      [ 0.4615, -0.1526,  0.1063, -0.2711,  0.0360, -0.0180, -0.2024, -0.4202],\n",
       "                      [-0.4001,  0.4803,  0.2025,  0.4628,  0.1575,  0.0763,  0.4491,  0.4539],\n",
       "                      [ 0.4925, -0.0566, -0.1152,  0.3377,  0.0783, -0.3436, -0.0939,  0.2755],\n",
       "                      [ 0.4424,  0.3951, -0.2187,  0.3436,  0.3672, -0.4895,  0.4845,  0.1164],\n",
       "                      [-0.1744, -0.0022, -0.0743, -0.0136, -0.0675,  0.3160,  0.1487, -0.3109],\n",
       "                      [-0.3170, -0.3963, -0.4400, -0.2623, -0.1692,  0.2465, -0.3919,  0.2436],\n",
       "                      [ 0.4086,  0.3978, -0.4697, -0.3775, -0.3986, -0.4104,  0.2623, -0.4196],\n",
       "                      [-0.4079,  0.2861, -0.0025, -0.0771, -0.0570, -0.0616,  0.1690,  0.1994],\n",
       "                      [ 0.3369, -0.1147,  0.0540, -0.1009, -0.4334, -0.4711,  0.4595, -0.3551],\n",
       "                      [ 0.3206,  0.1458, -0.3700, -0.4218,  0.1465, -0.4252,  0.4853,  0.4743],\n",
       "                      [ 0.3793,  0.3221,  0.1649,  0.2233, -0.3638,  0.4689,  0.4823,  0.2853],\n",
       "                      [ 0.1440, -0.0144,  0.3675, -0.2352,  0.1192,  0.0239, -0.1101, -0.0310],\n",
       "                      [-0.3362,  0.0695, -0.2701,  0.3289,  0.2081,  0.0551, -0.0839, -0.1795],\n",
       "                      [-0.4727,  0.4263, -0.1712,  0.1552, -0.0203, -0.2018,  0.1752,  0.0047],\n",
       "                      [ 0.1096,  0.4088, -0.2485, -0.1161,  0.0625, -0.4768,  0.0195,  0.2085]])),\n",
       "             ('convnorm.1.bnr1.module.weight',\n",
       "              tensor([1.0001, 1.0001, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      0.9999, 1.0001, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])),\n",
       "             ('convnorm.1.bnr1.module.bias',\n",
       "              tensor([ 6.7745e-05,  3.8578e-05, -3.5330e-05, -3.0938e-05,  3.8556e-05,\n",
       "                      -1.8656e-06, -4.0028e-05, -2.3618e-05, -4.6234e-06, -7.4399e-05,\n",
       "                       9.1081e-05, -4.3536e-05,  1.0193e-05,  5.0814e-05, -2.0043e-05,\n",
       "                       5.6888e-06])),\n",
       "             ('convnorm.1.bnr1.module.running_mean',\n",
       "              tensor([ 0.4145, -0.1334,  0.5141,  0.1705,  0.3996, -0.0586, -0.3947, -0.2933,\n",
       "                       0.0117, -0.1841,  0.0968,  0.5070,  0.0663, -0.0438, -0.0247, -0.0032])),\n",
       "             ('convnorm.1.bnr1.module.running_var',\n",
       "              tensor([0.1685, 0.0533, 0.4197, 0.0365, 0.2500, 0.0453, 1.1211, 0.0944, 0.0090,\n",
       "                      0.1006, 0.0349, 2.2084, 0.1219, 0.2386, 0.0573, 0.0394])),\n",
       "             ('convnorm.1.bnr1.module.num_batches_tracked', tensor(183549)),\n",
       "             ('convnorm.2.conv1.bias',\n",
       "              tensor([ 1.3039e-12,  1.8073e-12, -9.6261e-13,  3.6481e-12, -5.6250e-13,\n",
       "                       7.2649e-12, -3.7148e-12,  1.2416e-11, -5.7546e-12, -1.8619e-11,\n",
       "                      -1.1810e-11, -6.0803e-12,  8.8109e-13,  1.2736e-12,  1.6365e-12,\n",
       "                       3.0236e-12,  3.7029e-12,  1.4320e-12,  5.3596e-12,  2.4496e-12,\n",
       "                       1.2222e-12, -2.3493e-11,  4.5911e-12, -2.3581e-11, -7.7446e-12,\n",
       "                       6.6839e-14,  4.2362e-12, -2.8993e-13,  2.3947e-12, -5.1552e-13,\n",
       "                      -5.1824e-12, -6.0300e-12])),\n",
       "             ('convnorm.2.conv1.lin.weight',\n",
       "              tensor([[ 0.1467, -0.0869,  0.1650, -0.1835, -0.2090,  0.2014, -0.2849, -0.0605,\n",
       "                        0.0244,  0.2104, -0.1801,  0.1217,  0.3463, -0.2543, -0.1077,  0.2640],\n",
       "                      [-0.0004, -0.0106, -0.1747, -0.1297,  0.2495, -0.3196, -0.1149,  0.1211,\n",
       "                       -0.2726, -0.2675, -0.3219, -0.2439, -0.0889, -0.3450,  0.2966, -0.3090],\n",
       "                      [ 0.0301, -0.3180,  0.1845,  0.3177,  0.1632, -0.2948,  0.1693,  0.0757,\n",
       "                        0.0293,  0.1510,  0.0563, -0.3103,  0.0658, -0.2285, -0.0864,  0.3274],\n",
       "                      [-0.3131,  0.2590, -0.1333,  0.2093,  0.3400,  0.2238,  0.2213,  0.1599,\n",
       "                       -0.2037,  0.1267, -0.1137,  0.2006, -0.3387,  0.0588, -0.0052, -0.0276],\n",
       "                      [-0.0855, -0.1557,  0.2212, -0.0951,  0.1403,  0.2196, -0.1561,  0.2388,\n",
       "                       -0.2599,  0.3478,  0.1301,  0.0519, -0.0529,  0.0369, -0.0029,  0.1460],\n",
       "                      [-0.1919, -0.2826,  0.3065,  0.2676,  0.2394, -0.2754,  0.1634,  0.0106,\n",
       "                        0.3066, -0.0275,  0.0076, -0.0507, -0.0822,  0.2778, -0.2281,  0.2774],\n",
       "                      [-0.1137,  0.2912,  0.1557,  0.3250,  0.1804,  0.1576,  0.2858, -0.1537,\n",
       "                        0.3239, -0.2730,  0.3459,  0.1685,  0.0341,  0.2813, -0.1226, -0.3055],\n",
       "                      [-0.0399,  0.3004,  0.0087,  0.2561,  0.1670,  0.2053, -0.2424, -0.1219,\n",
       "                        0.0562, -0.3524, -0.0829, -0.1357,  0.0922, -0.1084, -0.1198,  0.1963],\n",
       "                      [ 0.2857, -0.2684,  0.0767, -0.0552,  0.1780, -0.0645,  0.0167, -0.1584,\n",
       "                        0.3122, -0.1084, -0.2268,  0.1205,  0.1847, -0.1266,  0.2561, -0.2703],\n",
       "                      [-0.1173, -0.0764, -0.1443, -0.1430,  0.3126, -0.3336, -0.3458,  0.0038,\n",
       "                       -0.0606,  0.0627,  0.0804, -0.0276, -0.0387, -0.1889, -0.0221, -0.2073],\n",
       "                      [-0.2499, -0.1151,  0.1275, -0.3113,  0.0708, -0.1761, -0.1089,  0.0161,\n",
       "                        0.1745,  0.1739,  0.2199,  0.0902, -0.2054, -0.3462,  0.0250, -0.2933],\n",
       "                      [ 0.0116,  0.1905, -0.3232, -0.2312,  0.1365,  0.2060,  0.1718,  0.0479,\n",
       "                       -0.2557,  0.2891, -0.2809, -0.2925, -0.0326,  0.0191,  0.2947, -0.3515],\n",
       "                      [ 0.0959,  0.3070,  0.0616, -0.2328, -0.0060,  0.2842,  0.1225,  0.3429,\n",
       "                        0.1838, -0.2331, -0.3371, -0.1516,  0.0826,  0.3414,  0.1611,  0.0223],\n",
       "                      [-0.0134,  0.3411,  0.2101, -0.0342,  0.3157,  0.0257, -0.0810,  0.2893,\n",
       "                        0.0997, -0.0885, -0.1764,  0.2225,  0.0957,  0.0565, -0.1472, -0.0036],\n",
       "                      [-0.0412,  0.1195, -0.2629, -0.3279,  0.1641, -0.1424, -0.2029, -0.0557,\n",
       "                        0.3153, -0.0612, -0.2317,  0.2926,  0.2548,  0.0038,  0.0194, -0.0319],\n",
       "                      [ 0.0982,  0.1371, -0.0206,  0.2967, -0.2434, -0.0645, -0.1439,  0.3492,\n",
       "                        0.2315, -0.2573,  0.1697,  0.2432,  0.2557,  0.3428, -0.2265, -0.2751],\n",
       "                      [ 0.0090,  0.0462, -0.2359,  0.3407,  0.0589, -0.3477, -0.0561,  0.2359,\n",
       "                       -0.1053,  0.0624,  0.3020,  0.0340,  0.0814,  0.1512,  0.1225,  0.2956],\n",
       "                      [-0.0093,  0.0515,  0.0644, -0.1474, -0.3452,  0.2452, -0.2854,  0.2200,\n",
       "                        0.2008, -0.0091,  0.0128, -0.2144, -0.2251,  0.3256, -0.2076, -0.3114],\n",
       "                      [-0.2962,  0.0136, -0.3462,  0.1798, -0.0936,  0.0124,  0.1434, -0.1865,\n",
       "                       -0.2674,  0.1357, -0.3400,  0.0939,  0.2307,  0.0994, -0.1395, -0.0790],\n",
       "                      [ 0.3372, -0.2339,  0.0078, -0.1258,  0.0912,  0.2673, -0.0975,  0.2883,\n",
       "                       -0.0168,  0.3404, -0.0794,  0.1047, -0.1143,  0.0762,  0.3469,  0.1176],\n",
       "                      [ 0.1061, -0.2477,  0.2591, -0.0898, -0.3467,  0.0522,  0.2151,  0.0776,\n",
       "                       -0.0957, -0.3528, -0.0864,  0.2859, -0.1667,  0.2957, -0.1415,  0.2589],\n",
       "                      [ 0.1070,  0.0114, -0.0177, -0.3366, -0.1966, -0.0542,  0.0561, -0.1397,\n",
       "                        0.2465, -0.2627,  0.3200,  0.2895, -0.2204, -0.0461, -0.1452,  0.0572],\n",
       "                      [-0.0881, -0.3162, -0.3183, -0.0517, -0.1455, -0.1359,  0.3336,  0.0337,\n",
       "                        0.2881, -0.0803, -0.3082, -0.3085,  0.2005, -0.0107, -0.1401, -0.1568],\n",
       "                      [ 0.0759,  0.0421,  0.2604, -0.2977, -0.3339, -0.0733, -0.3279, -0.2926,\n",
       "                        0.0798,  0.0179,  0.1038,  0.2423, -0.1686,  0.2337,  0.0045,  0.2047],\n",
       "                      [ 0.1451,  0.0196,  0.1486,  0.1548, -0.1176, -0.0296,  0.1772, -0.3307,\n",
       "                       -0.1071, -0.2951,  0.1165, -0.0416,  0.1387, -0.1305, -0.3290,  0.2002],\n",
       "                      [ 0.0435,  0.2807,  0.0963,  0.0967,  0.1714,  0.1923, -0.1785,  0.1265,\n",
       "                        0.0624,  0.2361, -0.2370,  0.0171, -0.3117,  0.1138,  0.1350, -0.2433],\n",
       "                      [ 0.0963,  0.3393, -0.0612, -0.1960, -0.3324, -0.0996,  0.1463,  0.1257,\n",
       "                        0.2698,  0.1726,  0.0270, -0.0045,  0.2541, -0.3338, -0.0272,  0.0195],\n",
       "                      [-0.0732, -0.2406, -0.2950, -0.0456, -0.1085, -0.0670, -0.2070, -0.0602,\n",
       "                       -0.1090, -0.0086,  0.1371,  0.2421, -0.1093,  0.2897,  0.0846, -0.1260],\n",
       "                      [ 0.1125,  0.1083,  0.2632, -0.0080, -0.1031,  0.0113,  0.2233,  0.1337,\n",
       "                        0.0864,  0.0105, -0.1475,  0.2474, -0.1734,  0.0775, -0.1948,  0.0448],\n",
       "                      [ 0.0722, -0.2165,  0.2877, -0.2698,  0.2049,  0.0758,  0.1197,  0.1899,\n",
       "                        0.1826,  0.2251,  0.2188, -0.0866,  0.2933, -0.0651, -0.2518,  0.1761],\n",
       "                      [-0.1634,  0.0774,  0.1548, -0.3110, -0.2720, -0.2463, -0.3427, -0.1336,\n",
       "                        0.3393, -0.1835,  0.0072,  0.0242,  0.0633,  0.2928,  0.3216, -0.3378],\n",
       "                      [ 0.1797, -0.0241,  0.0528, -0.0353,  0.0792,  0.1502,  0.2233, -0.1553,\n",
       "                        0.1821,  0.0365, -0.3306, -0.2137,  0.3180,  0.0107,  0.1910,  0.0432]])),\n",
       "             ('convnorm.2.bnr1.module.weight',\n",
       "              tensor([1.0000, 1.0000, 1.0001, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000,\n",
       "                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000])),\n",
       "             ('convnorm.2.bnr1.module.bias',\n",
       "              tensor([-1.3068e-05, -3.0163e-05,  3.7359e-05,  2.1024e-05, -1.4108e-05,\n",
       "                       2.0194e-05,  7.4082e-05, -8.1570e-05,  4.8273e-05,  1.9375e-05,\n",
       "                      -1.8189e-05, -2.3785e-05,  2.9855e-05, -3.5063e-05,  2.9966e-05,\n",
       "                      -2.3467e-05,  6.5622e-06, -4.6426e-06, -2.4944e-05,  1.1375e-05,\n",
       "                       3.3349e-05, -2.4044e-05,  5.7956e-05, -3.6506e-05, -2.5473e-05,\n",
       "                      -2.2061e-05,  3.9450e-06, -1.9688e-05, -3.7832e-05, -1.1325e-05,\n",
       "                       4.6585e-05, -9.9407e-06])),\n",
       "             ('convnorm.2.bnr1.module.running_mean',\n",
       "              tensor([ 0.0072, -0.3609,  0.0789,  0.1720,  0.1749,  0.1209,  0.3013,  0.0134,\n",
       "                      -0.0081, -0.2332, -0.1870, -0.0433,  0.2127,  0.2504, -0.0746,  0.2102,\n",
       "                       0.2310, -0.0992, -0.1670,  0.2813, -0.0348, -0.1191, -0.2672, -0.0893,\n",
       "                      -0.0855,  0.1718,  0.0887, -0.1550,  0.1475,  0.2225, -0.1823,  0.1134])),\n",
       "             ('convnorm.2.bnr1.module.running_var',\n",
       "              tensor([0.5129, 0.9576, 0.1425, 0.1837, 0.7475, 0.1803, 0.6135, 0.0573, 0.2479,\n",
       "                      0.1304, 0.0770, 0.1441, 0.2576, 1.1994, 0.1077, 0.3471, 0.1954, 0.1104,\n",
       "                      0.5535, 0.7383, 0.2062, 0.0728, 1.4466, 0.0527, 0.0961, 0.2958, 0.2834,\n",
       "                      0.2979, 0.1985, 1.2852, 0.3220, 0.1697])),\n",
       "             ('convnorm.2.bnr1.module.num_batches_tracked', tensor(183549)),\n",
       "             ('convnorm.3.conv1.bias',\n",
       "              tensor([ 1.4833e-12, -4.5988e-12,  1.8719e-12, -5.6881e-12,  9.4211e-12,\n",
       "                      -4.5341e-12, -9.1638e-12,  1.5868e-12,  7.9033e-12,  8.0882e-12,\n",
       "                      -1.2504e-12,  3.5624e-12, -1.0823e-12, -1.5056e-13,  5.3112e-12,\n",
       "                      -8.0591e-13,  1.3655e-12, -3.2067e-12, -7.9919e-13, -2.3232e-12,\n",
       "                      -2.0270e-12,  9.0012e-13,  1.9389e-12, -2.7416e-12, -1.1488e-11,\n",
       "                      -1.3433e-12, -7.7811e-12, -3.7483e-12,  2.0257e-12, -5.5443e-12,\n",
       "                      -1.0283e-12, -3.4572e-12,  8.2664e-13,  1.0708e-13, -2.4913e-12,\n",
       "                      -8.4659e-12,  1.7272e-12,  1.6652e-13, -3.6709e-12, -4.5487e-12,\n",
       "                       8.7898e-13, -4.3850e-12, -2.3741e-12,  5.1715e-12,  6.6129e-12,\n",
       "                      -5.2378e-12, -5.2549e-12, -3.0069e-12,  4.9770e-12,  3.1654e-12,\n",
       "                       7.4098e-13,  4.6255e-12,  1.1896e-11,  6.1056e-12,  1.5451e-13,\n",
       "                      -2.0176e-12,  1.2803e-12, -5.5820e-12,  1.0336e-12,  3.0573e-12,\n",
       "                      -5.9433e-13, -1.3675e-12, -3.7071e-12,  2.3926e-12])),\n",
       "             ('convnorm.3.conv1.lin.weight',\n",
       "              tensor([[-0.0834,  0.1938,  0.0073,  ...,  0.1164, -0.1931, -0.2100],\n",
       "                      [-0.2011,  0.0618,  0.0972,  ..., -0.0041,  0.1233,  0.1607],\n",
       "                      [ 0.0471,  0.0326,  0.0513,  ...,  0.2334,  0.0668, -0.0173],\n",
       "                      ...,\n",
       "                      [-0.0701,  0.1572,  0.0850,  ...,  0.1746,  0.0677,  0.1643],\n",
       "                      [-0.0852, -0.1779, -0.1108,  ..., -0.0324, -0.0100,  0.1563],\n",
       "                      [-0.0411, -0.2326,  0.0604,  ..., -0.0790, -0.2197,  0.1227]])),\n",
       "             ('convnorm.3.bnr1.module.weight',\n",
       "              tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "                      1.0000])),\n",
       "             ('convnorm.3.bnr1.module.bias',\n",
       "              tensor([-1.8356e-05,  4.2746e-05, -4.6433e-06, -2.4175e-05,  8.1873e-06,\n",
       "                      -2.5472e-05,  9.7503e-07,  1.3320e-05,  4.4537e-06, -6.9548e-06,\n",
       "                       6.6976e-06, -6.9969e-07, -5.8564e-06, -2.8583e-05,  8.9529e-05,\n",
       "                       8.0095e-06,  1.2275e-05, -5.6901e-06, -7.4429e-06, -1.6526e-05,\n",
       "                      -3.6653e-05,  3.6305e-05, -5.2257e-06,  1.7573e-06,  2.4180e-05,\n",
       "                       3.0210e-06, -6.4184e-06, -1.5482e-05, -2.8335e-06,  1.7435e-05,\n",
       "                      -2.3594e-05, -1.2363e-05, -2.3575e-07,  1.2746e-05,  3.0632e-05,\n",
       "                       2.7547e-05,  1.7869e-05, -1.8325e-05,  3.1903e-06, -1.4451e-05,\n",
       "                      -7.2369e-07, -7.9867e-06, -1.9056e-05,  5.3704e-05, -2.0974e-05,\n",
       "                      -2.4514e-05,  1.4020e-05, -1.0180e-05,  2.2387e-05, -2.6209e-05,\n",
       "                      -9.4326e-06,  1.1516e-06, -8.7843e-07, -8.1995e-06, -1.0945e-05,\n",
       "                       2.3859e-05,  1.8282e-05, -7.3054e-06, -2.4178e-05,  1.7918e-05,\n",
       "                      -6.5969e-06, -5.7845e-06,  2.0094e-05, -7.1791e-06])),\n",
       "             ('convnorm.3.bnr1.module.running_mean',\n",
       "              tensor([-0.1839, -0.0470, -0.0695,  0.0097, -0.0093,  0.0428, -0.0290,  0.1323,\n",
       "                      -0.1505, -0.0110,  0.0831, -0.0013, -0.0694,  0.1088,  0.0426, -0.0753,\n",
       "                      -0.0224, -0.0326,  0.0265, -0.0636, -0.0094,  0.0816,  0.0547,  0.1253,\n",
       "                      -0.2585, -0.2009, -0.0731, -0.0663, -0.1109, -0.1311, -0.1635,  0.0315,\n",
       "                       0.2591, -0.2308, -0.1591, -0.1789,  0.0607,  0.1699, -0.0852,  0.0076,\n",
       "                       0.0676, -0.0015,  0.2390, -0.0286, -0.0634,  0.0123,  0.0058,  0.0582,\n",
       "                       0.1382,  0.0190,  0.1869,  0.0140, -0.1184, -0.1586,  0.1898,  0.1219,\n",
       "                       0.0842,  0.0985, -0.0060, -0.1172,  0.0876,  0.0007,  0.0578, -0.1922])),\n",
       "             ('convnorm.3.bnr1.module.running_var',\n",
       "              tensor([0.2445, 0.1708, 0.3933, 0.2186, 0.0552, 0.2196, 0.2602, 0.9591, 0.0915,\n",
       "                      0.1584, 0.3837, 0.1987, 0.2271, 0.1437, 0.0919, 0.1648, 0.1075, 0.0808,\n",
       "                      0.1534, 0.1365, 0.2466, 0.1051, 0.1079, 0.1146, 0.1319, 0.7387, 0.4114,\n",
       "                      0.1877, 0.3762, 0.3334, 0.3754, 0.1648, 1.4915, 0.8502, 0.3974, 0.2823,\n",
       "                      0.4367, 0.6454, 0.1645, 0.2999, 0.1015, 0.1628, 0.2556, 0.0768, 0.1029,\n",
       "                      0.1634, 0.1524, 0.1711, 0.1632, 0.2265, 0.6806, 0.1306, 0.1420, 0.0693,\n",
       "                      1.1938, 0.3148, 0.4050, 0.2593, 0.2384, 0.4116, 0.5391, 0.1843, 0.0496,\n",
       "                      0.2167])),\n",
       "             ('convnorm.3.bnr1.module.num_batches_tracked', tensor(183549)),\n",
       "             ('linears.0.fc1.weight',\n",
       "              tensor([[-0.3305,  0.0107, -0.3767,  0.0180],\n",
       "                      [ 0.1230, -0.4988,  0.3854,  0.3738],\n",
       "                      [-0.1243,  0.4641,  0.0790, -0.2422],\n",
       "                      [-0.3626, -0.3964, -0.0153,  0.3894]])),\n",
       "             ('linears.0.fc1.bias',\n",
       "              tensor([ 0.0096, -0.2619, -0.4157, -0.2809])),\n",
       "             ('linears.0.fc2.weight',\n",
       "              tensor([[ 0.1307,  0.2007, -0.0010, -0.3343],\n",
       "                      [ 0.4648, -0.0783,  0.2841,  0.0197]])),\n",
       "             ('linears.0.fc2.bias', tensor([-0.2623,  0.2649])),\n",
       "             ('linears.1.fc1.weight',\n",
       "              tensor([[-0.0229, -0.0477,  0.2895, -0.1905,  0.0179,  0.0668, -0.2251,  0.1913],\n",
       "                      [-0.0794,  0.1120, -0.1117,  0.1971, -0.2035, -0.3118,  0.2839,  0.3214],\n",
       "                      [-0.1266,  0.3730,  0.0776,  0.1855,  0.2366,  0.0926,  0.1602,  0.0554],\n",
       "                      [ 0.2556,  0.3259,  0.2132,  0.1667, -0.2635,  0.3033,  0.2042,  0.3500],\n",
       "                      [-0.1599,  0.2239,  0.2204,  0.3320, -0.0406, -0.2783, -0.0358,  0.3162],\n",
       "                      [-0.2779, -0.3103,  0.0763,  0.1695, -0.2703,  0.1555,  0.1872, -0.1186],\n",
       "                      [-0.1886,  0.0591,  0.1723, -0.0544, -0.2134, -0.3495, -0.0608, -0.1138],\n",
       "                      [ 0.2289,  0.0103, -0.0847,  0.0530,  0.2156,  0.0081,  0.3334, -0.1260]])),\n",
       "             ('linears.1.fc1.bias',\n",
       "              tensor([ 0.0797,  0.2362,  0.3668, -0.2293, -0.3165, -0.1934, -0.2462, -0.1693])),\n",
       "             ('linears.1.fc2.weight',\n",
       "              tensor([[ 0.2395,  0.2020,  0.1703, -0.0989,  0.1272,  0.1461, -0.0046, -0.3310],\n",
       "                      [-0.2528,  0.0364, -0.1260,  0.3512, -0.3524,  0.2170,  0.2758,  0.3024],\n",
       "                      [-0.1146,  0.1288,  0.1294, -0.1016, -0.2772,  0.1277, -0.1320, -0.2891],\n",
       "                      [ 0.2727,  0.1982, -0.0967, -0.0263, -0.1547, -0.1612,  0.0800,  0.0275]])),\n",
       "             ('linears.1.fc2.bias',\n",
       "              tensor([ 0.3707, -0.2379, -0.3014, -0.0594])),\n",
       "             ('linears.2.fc1.weight',\n",
       "              tensor([[ 0.1445, -0.1824,  0.2117, -0.1506, -0.0759,  0.1160,  0.1933, -0.0637,\n",
       "                        0.1050, -0.0837, -0.2406, -0.0922, -0.1193, -0.0185, -0.1171,  0.1814],\n",
       "                      [ 0.0308,  0.1279,  0.1716, -0.1907,  0.1219, -0.1050, -0.0898, -0.0439,\n",
       "                        0.2065, -0.0828, -0.1387,  0.0157, -0.1055, -0.0285,  0.0115,  0.1979],\n",
       "                      [ 0.2542,  0.0600,  0.2309,  0.0286, -0.1744, -0.1325, -0.1201, -0.0227,\n",
       "                       -0.2385, -0.0102,  0.0476, -0.1829, -0.0009, -0.0722,  0.0224, -0.0181],\n",
       "                      [ 0.0201,  0.1386,  0.1155, -0.1716,  0.1284,  0.1686,  0.2480,  0.2374,\n",
       "                       -0.2117, -0.1889, -0.0508, -0.0366,  0.2263, -0.1341,  0.1289, -0.2490],\n",
       "                      [-0.1258,  0.2395,  0.0575, -0.1582,  0.1726, -0.1640,  0.1357, -0.0797,\n",
       "                        0.1688,  0.2757,  0.1917,  0.1737,  0.0500, -0.1570, -0.2132,  0.0051],\n",
       "                      [-0.0964, -0.0844,  0.0758,  0.0617, -0.0336,  0.0856,  0.0283, -0.1576,\n",
       "                        0.0287, -0.1072,  0.0640,  0.1618, -0.0149, -0.2356, -0.2244, -0.2213],\n",
       "                      [ 0.1692,  0.1689, -0.1506,  0.1714, -0.1650, -0.1552,  0.0302,  0.2052,\n",
       "                        0.1041, -0.0625, -0.1283,  0.0045, -0.0519,  0.1610,  0.0971, -0.0358],\n",
       "                      [ 0.2245, -0.2011,  0.1199, -0.1498, -0.1521, -0.2387, -0.0315,  0.1260,\n",
       "                        0.1347, -0.1534,  0.1655, -0.0880,  0.1447, -0.0838, -0.1001, -0.1950],\n",
       "                      [-0.0574,  0.0347,  0.1111, -0.1547, -0.2437, -0.2363, -0.0685,  0.2086,\n",
       "                       -0.1477, -0.1414, -0.2385, -0.1109, -0.0494,  0.1169, -0.1832,  0.0643],\n",
       "                      [-0.0753,  0.2306, -0.0519,  0.2052,  0.0261, -0.0425,  0.2232,  0.0508,\n",
       "                       -0.1941, -0.1770, -0.0912,  0.1161,  0.0899,  0.0224, -0.2086, -0.2390],\n",
       "                      [-0.1119,  0.1082,  0.0882, -0.1541,  0.1781,  0.2307, -0.2194, -0.2036,\n",
       "                       -0.0616,  0.2530, -0.1193,  0.1906,  0.1964,  0.1886,  0.2634,  0.2086],\n",
       "                      [-0.1872,  0.0975,  0.1051, -0.1357, -0.1130,  0.1040,  0.0331, -0.1015,\n",
       "                        0.2260, -0.2087, -0.1043, -0.0692,  0.1432,  0.2050, -0.0710,  0.1072],\n",
       "                      [ 0.2190, -0.2009,  0.0966,  0.1124,  0.0190,  0.1508,  0.2301,  0.1277,\n",
       "                        0.0105, -0.1407, -0.0419, -0.2428, -0.0797,  0.0885, -0.0867, -0.1397],\n",
       "                      [ 0.0506,  0.1502, -0.0438,  0.0603,  0.1867,  0.1022, -0.0247,  0.1404,\n",
       "                       -0.2479, -0.1324,  0.1274, -0.1546, -0.1458,  0.1448,  0.0354,  0.1123],\n",
       "                      [-0.0077,  0.1311, -0.2164,  0.1019, -0.0075, -0.0047, -0.1423,  0.1601,\n",
       "                        0.1123,  0.1650,  0.0519,  0.2224, -0.2027, -0.0304,  0.1875,  0.1164],\n",
       "                      [-0.1455, -0.0334, -0.0605,  0.1547, -0.0545,  0.1440, -0.0281,  0.1209,\n",
       "                       -0.0445, -0.2093, -0.0767,  0.1295,  0.0803,  0.1405,  0.0318, -0.1027]])),\n",
       "             ('linears.2.fc1.bias',\n",
       "              tensor([-0.0634,  0.1484,  0.0816, -0.2263,  0.2589, -0.2482, -0.0064, -0.0041,\n",
       "                      -0.2196,  0.1601, -0.0122, -0.1509,  0.0516,  0.0465, -0.0610,  0.1802])),\n",
       "             ('linears.2.fc2.weight',\n",
       "              tensor([[-0.2362,  0.0498, -0.1120,  0.2459, -0.2885,  0.2225,  0.0016, -0.0476,\n",
       "                        0.1566,  0.1443, -0.1930,  0.1641, -0.0759, -0.0708,  0.1061, -0.1170],\n",
       "                      [ 0.0685, -0.0316,  0.0640, -0.2413,  0.2664, -0.1047, -0.1594,  0.0582,\n",
       "                       -0.0984,  0.0754, -0.0049,  0.2323, -0.1284, -0.1848, -0.0037,  0.0321],\n",
       "                      [-0.1946, -0.1097, -0.0254, -0.1006,  0.0138, -0.2483,  0.1894,  0.0119,\n",
       "                        0.1767, -0.0014,  0.2072, -0.1193,  0.1846,  0.0844, -0.0773, -0.1405],\n",
       "                      [-0.2127, -0.0395, -0.0807, -0.2010,  0.1604,  0.1949,  0.1588, -0.1342,\n",
       "                       -0.0533, -0.0030, -0.0762,  0.1767,  0.1842, -0.1364, -0.2301, -0.0515],\n",
       "                      [-0.1872,  0.1797,  0.0046, -0.1367, -0.0062, -0.2361, -0.1625,  0.2449,\n",
       "                       -0.1278, -0.1130,  0.1956, -0.1989,  0.0658, -0.2448, -0.1118,  0.1449],\n",
       "                      [ 0.0686,  0.1966, -0.0805, -0.0211,  0.0480, -0.2311,  0.2097,  0.2412,\n",
       "                       -0.0335, -0.0483,  0.1273, -0.0908,  0.0234, -0.0290, -0.1818, -0.1103],\n",
       "                      [-0.0722,  0.0869, -0.1987,  0.1551, -0.0621, -0.1324,  0.0813,  0.0555,\n",
       "                       -0.0919,  0.1357,  0.2556,  0.0849, -0.0763, -0.1556,  0.1134,  0.2565],\n",
       "                      [-0.0786, -0.0229, -0.1593,  0.1105,  0.1437,  0.2482,  0.1031, -0.0861,\n",
       "                       -0.1019,  0.1005,  0.2521, -0.1194,  0.2251, -0.1790, -0.2036, -0.1963]])),\n",
       "             ('linears.2.fc2.bias',\n",
       "              tensor([-0.2237,  0.2626,  0.2125, -0.0778,  0.0609, -0.1263,  0.2577,  0.1412])),\n",
       "             ('linears.3.fc1.weight',\n",
       "              tensor([[ 0.0633,  0.0366, -0.0734,  ..., -0.1578, -0.0206, -0.0789],\n",
       "                      [ 0.0588,  0.1418, -0.0147,  ..., -0.1000, -0.0194,  0.1431],\n",
       "                      [ 0.1216, -0.0467, -0.0147,  ...,  0.1465, -0.0911, -0.1083],\n",
       "                      ...,\n",
       "                      [-0.0192,  0.0942, -0.0689,  ...,  0.0323, -0.1492, -0.0188],\n",
       "                      [ 0.1657, -0.0938,  0.1685,  ...,  0.0443,  0.0605, -0.0282],\n",
       "                      [-0.0003, -0.0788,  0.1158,  ..., -0.1457,  0.0031,  0.0631]])),\n",
       "             ('linears.3.fc1.bias',\n",
       "              tensor([-0.1618,  0.0282, -0.0823, -0.0323, -0.0545, -0.0294, -0.0242,  0.0926,\n",
       "                      -0.0299,  0.1102, -0.0657,  0.0512, -0.0645,  0.1503, -0.1094, -0.1150,\n",
       "                       0.0844,  0.0317, -0.1475, -0.0439,  0.0138, -0.1164,  0.1357,  0.1843,\n",
       "                      -0.0385,  0.0367,  0.0905,  0.1466, -0.1728, -0.0758, -0.1693,  0.0730])),\n",
       "             ('linears.3.fc2.weight',\n",
       "              tensor([[ 0.1015, -0.1294, -0.0568, -0.0278,  0.0846,  0.0299,  0.0250, -0.1937,\n",
       "                       -0.0041,  0.1117, -0.0240, -0.1817,  0.1303,  0.0756,  0.0249,  0.1493,\n",
       "                        0.0258,  0.1065, -0.1744,  0.1554,  0.1461,  0.1668, -0.1807, -0.0894,\n",
       "                       -0.0094,  0.1044,  0.0864, -0.0111, -0.1073, -0.1693,  0.0207, -0.0599],\n",
       "                      [ 0.0154,  0.0022,  0.1600, -0.0754, -0.0596,  0.1794, -0.1312, -0.1310,\n",
       "                        0.0881,  0.1321, -0.0458,  0.1691, -0.0550,  0.1683,  0.1257, -0.0941,\n",
       "                        0.0701,  0.1475, -0.0420,  0.0728,  0.1195,  0.1239, -0.1335,  0.1150,\n",
       "                        0.0789, -0.1377, -0.0427,  0.1561, -0.0773, -0.0565, -0.1197, -0.1005],\n",
       "                      [-0.1318,  0.0812,  0.0055,  0.1034, -0.0313, -0.1524,  0.1460, -0.0060,\n",
       "                       -0.0543, -0.0693,  0.0772, -0.1271, -0.0111,  0.0304, -0.1092,  0.0376,\n",
       "                       -0.1339,  0.0742,  0.1378,  0.1184,  0.1231,  0.1257,  0.0186, -0.0797,\n",
       "                        0.0077,  0.0994, -0.1714,  0.0078, -0.0689, -0.0301, -0.0867, -0.0428],\n",
       "                      [ 0.1474,  0.1722,  0.0124, -0.1514,  0.0542, -0.0292, -0.0329,  0.0228,\n",
       "                        0.1180, -0.1462,  0.1617,  0.0993, -0.0416,  0.0448,  0.1089,  0.0918,\n",
       "                       -0.1453, -0.0784,  0.1032,  0.1412, -0.0004,  0.0445, -0.1349, -0.1077,\n",
       "                       -0.1385,  0.0271,  0.0639, -0.0476, -0.0417, -0.1766, -0.0470, -0.1597],\n",
       "                      [ 0.0807,  0.1357, -0.1397, -0.1709, -0.0225, -0.0025, -0.0504, -0.1360,\n",
       "                        0.0630,  0.0563, -0.0167,  0.1395, -0.0859, -0.0199,  0.1420, -0.0664,\n",
       "                       -0.0255, -0.0888, -0.0996,  0.1689,  0.0586, -0.0606,  0.1775,  0.0477,\n",
       "                       -0.0499,  0.1716, -0.0571,  0.1226, -0.1632, -0.0884, -0.0040,  0.1350],\n",
       "                      [ 0.0833,  0.1681,  0.1314, -0.0572, -0.0075,  0.1022,  0.1336, -0.1484,\n",
       "                        0.0139, -0.0676,  0.0373,  0.0289, -0.1093, -0.1309,  0.1082,  0.1231,\n",
       "                       -0.0550,  0.1604, -0.1047,  0.1289,  0.1750, -0.1753, -0.0723,  0.1495,\n",
       "                        0.0662, -0.1520,  0.1476, -0.0644,  0.0316, -0.0612, -0.1438,  0.0376],\n",
       "                      [ 0.1687,  0.0149,  0.1390,  0.0753, -0.0292,  0.1581,  0.1673,  0.1835,\n",
       "                        0.1191, -0.0139, -0.0174, -0.1307, -0.0931, -0.1459,  0.0711,  0.1353,\n",
       "                       -0.0613, -0.0965, -0.0561, -0.1421,  0.1559, -0.1635,  0.0642,  0.0702,\n",
       "                       -0.1273, -0.0668,  0.0089, -0.0409,  0.0340,  0.1017, -0.1511,  0.1107],\n",
       "                      [-0.1486,  0.0507,  0.0547,  0.1290,  0.1267,  0.0935, -0.0189, -0.0112,\n",
       "                       -0.0177,  0.1401, -0.1281,  0.1600,  0.1022,  0.1651, -0.0468,  0.1518,\n",
       "                        0.1304,  0.0407, -0.1658,  0.1604,  0.0465,  0.0229, -0.1536, -0.0963,\n",
       "                        0.1002,  0.0161,  0.0647, -0.1076, -0.0542,  0.0745, -0.0287,  0.1294],\n",
       "                      [ 0.0253, -0.0875, -0.1257, -0.1694,  0.0571,  0.0778,  0.0378,  0.0604,\n",
       "                        0.0415,  0.0233,  0.0154,  0.1601,  0.1406, -0.0300, -0.0370,  0.0386,\n",
       "                        0.0028,  0.0244, -0.0712,  0.1709,  0.0632,  0.0907, -0.1354, -0.0342,\n",
       "                        0.1117, -0.0947,  0.1778,  0.1016, -0.0709, -0.1574,  0.0957, -0.1420],\n",
       "                      [ 0.1467,  0.1346, -0.0146,  0.0701, -0.0764, -0.0368, -0.1179,  0.0844,\n",
       "                        0.1252,  0.1382, -0.0761, -0.0173, -0.1074,  0.1048, -0.1701, -0.0386,\n",
       "                       -0.0500, -0.0785, -0.0834, -0.1290,  0.1288,  0.0536, -0.1045, -0.1270,\n",
       "                        0.0884,  0.1455, -0.1570,  0.1641, -0.0444,  0.0688, -0.0467, -0.1442],\n",
       "                      [-0.1332,  0.1321,  0.0810, -0.0643,  0.0251, -0.0069, -0.0154,  0.0847,\n",
       "                       -0.0765, -0.1433,  0.0320,  0.1181, -0.0969, -0.1153, -0.1271,  0.0745,\n",
       "                       -0.0019,  0.0296, -0.1654, -0.1665,  0.1611,  0.0946, -0.0485,  0.0766,\n",
       "                       -0.1596, -0.1526, -0.1140,  0.1052,  0.0073, -0.1230, -0.0403, -0.0210],\n",
       "                      [-0.0790,  0.0973, -0.1307,  0.0389, -0.0441, -0.1508,  0.0038, -0.0389,\n",
       "                       -0.0051,  0.0954, -0.1636, -0.0671,  0.0229, -0.1588, -0.0939, -0.0860,\n",
       "                       -0.0360,  0.1389, -0.0362, -0.0564,  0.1415, -0.1475, -0.1255,  0.1858,\n",
       "                       -0.0731,  0.1593,  0.0753, -0.1424,  0.0490, -0.0740,  0.0283, -0.0482],\n",
       "                      [-0.0610,  0.0572, -0.0147, -0.0352, -0.0064, -0.0273, -0.0695, -0.0568,\n",
       "                        0.1008,  0.1313,  0.1558,  0.0473,  0.0835, -0.0782, -0.1570, -0.0113,\n",
       "                       -0.0130, -0.0727, -0.0595, -0.1269,  0.0237, -0.0891, -0.0712,  0.1425,\n",
       "                        0.1726, -0.0357, -0.0369,  0.0162, -0.1187, -0.1112, -0.0634, -0.0350],\n",
       "                      [-0.0242,  0.0716, -0.0096, -0.1080, -0.1307, -0.1444, -0.0251, -0.0613,\n",
       "                        0.0607, -0.1071,  0.0725, -0.1640, -0.0994, -0.0531, -0.0771,  0.1602,\n",
       "                        0.0012,  0.1703,  0.1375, -0.1549, -0.1356, -0.1161,  0.1042, -0.0424,\n",
       "                        0.0671,  0.0503, -0.1285,  0.0514,  0.1327, -0.1356, -0.1069,  0.1536],\n",
       "                      [-0.0974,  0.0243, -0.1683,  0.0398,  0.0195, -0.0414,  0.0609,  0.1334,\n",
       "                        0.0453, -0.0250, -0.1098, -0.0641,  0.1114, -0.0949,  0.1576, -0.0386,\n",
       "                        0.0520, -0.0178,  0.0650,  0.1453,  0.0582,  0.0462,  0.0419, -0.1071,\n",
       "                       -0.0834,  0.0510,  0.0254,  0.1045, -0.0742,  0.0942,  0.0201,  0.1414],\n",
       "                      [ 0.0947,  0.0559,  0.0503,  0.0572,  0.0445, -0.0324, -0.0098, -0.0211,\n",
       "                       -0.0757, -0.1054,  0.0798,  0.1336,  0.1313,  0.1005,  0.0715,  0.0651,\n",
       "                       -0.1279,  0.0584,  0.1381, -0.0961, -0.1196,  0.0635, -0.1725, -0.0847,\n",
       "                       -0.0876,  0.1385, -0.0275, -0.1491, -0.1058, -0.1079, -0.0493,  0.0764]])),\n",
       "             ('linears.3.fc2.bias',\n",
       "              tensor([ 0.0183,  0.1472, -0.0898,  0.1348, -0.0021,  0.1548, -0.0104, -0.1836,\n",
       "                       0.1406,  0.1032,  0.0574,  0.1403,  0.1334, -0.0893, -0.0166,  0.0512])),\n",
       "             ('linears.4.fc1.weight',\n",
       "              tensor([[ 0.0488, -0.0315, -0.0350,  ...,  0.0268,  0.0222, -0.0646],\n",
       "                      [ 0.0811, -0.0085, -0.0923,  ...,  0.0064, -0.0274,  0.0293],\n",
       "                      [ 0.0807, -0.0331, -0.0313,  ..., -0.0780, -0.0173, -0.0105],\n",
       "                      ...,\n",
       "                      [-0.0546, -0.0157,  0.0062,  ..., -0.1137,  0.0443,  0.1217],\n",
       "                      [-0.0939,  0.0869, -0.1187,  ...,  0.0745,  0.0117,  0.0143],\n",
       "                      [ 0.0509, -0.0186,  0.0388,  ..., -0.0141, -0.1011,  0.1174]])),\n",
       "             ('linears.4.fc1.bias',\n",
       "              tensor([ 0.0220,  0.0016, -0.0841, -0.0770, -0.0819, -0.0388,  0.0498, -0.1117,\n",
       "                       0.0614,  0.0444, -0.0198,  0.0985,  0.0375,  0.0443, -0.0827, -0.1114,\n",
       "                      -0.0051, -0.0570, -0.1083, -0.0195, -0.0148, -0.0647, -0.0907,  0.0259,\n",
       "                      -0.0568,  0.1133, -0.0257,  0.0206,  0.1269, -0.0744, -0.0992, -0.1093,\n",
       "                      -0.1089, -0.0513,  0.0027, -0.0948, -0.1148,  0.0887,  0.0240,  0.1186,\n",
       "                       0.0212,  0.0631,  0.0569,  0.0266,  0.1430,  0.0176,  0.0900,  0.1061,\n",
       "                       0.0563,  0.0837, -0.1037, -0.0060,  0.1146,  0.0694, -0.0898, -0.0786,\n",
       "                       0.0059, -0.0898, -0.0315,  0.0797, -0.0439,  0.0290, -0.0738,  0.0983])),\n",
       "             ('linears.4.fc2.weight',\n",
       "              tensor([[-0.1229, -0.0460,  0.0807,  ..., -0.1078,  0.1237, -0.0251],\n",
       "                      [-0.0732, -0.0825, -0.0446,  ...,  0.1181, -0.0714,  0.0761],\n",
       "                      [ 0.0139,  0.1104, -0.1124,  ...,  0.0027,  0.0085, -0.1299],\n",
       "                      ...,\n",
       "                      [-0.0758,  0.0563, -0.0327,  ..., -0.1160,  0.1219,  0.0106],\n",
       "                      [ 0.1149,  0.0983,  0.0187,  ..., -0.0227,  0.0637,  0.0642],\n",
       "                      [ 0.0470, -0.1031, -0.0988,  ...,  0.0733, -0.1055, -0.0356]])),\n",
       "             ('linears.4.fc2.bias',\n",
       "              tensor([-0.1154, -0.0211, -0.0905, -0.1050,  0.1013, -0.1105,  0.0771,  0.0231,\n",
       "                       0.1160, -0.0597, -0.0212, -0.1082,  0.0054,  0.0900,  0.0235,  0.0844,\n",
       "                      -0.0009, -0.0296,  0.0459, -0.0254,  0.0975,  0.0532, -0.1248,  0.0620,\n",
       "                       0.1008,  0.0392, -0.0414, -0.0417, -0.0660,  0.0737,  0.0654,  0.0880]))])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights have been successfully loaded from checkpoint.\n"
     ]
    }
   ],
   "source": [
    "# # Compare the state dictionaries\n",
    "# for param_tensor in model.state_dict():\n",
    "#     if not torch.equal(initial_dct_weights[param_tensor], model.state_dict()[param_tensor]):\n",
    "#         print(f\"Weights for {param_tensor} have been updated.\")\n",
    "        \n",
    "#     else:\n",
    "#         print(f\"Weights for {param_tensor} remain unchanged.\")\n",
    "\n",
    "# Alternatively, check if any parameter has changed\n",
    "if any(not torch.equal(initial_dct_weights[param], model.state_dict()[param]) for param in model.state_dict()):\n",
    "    print(\"Model weights have been successfully loaded from checkpoint.\")\n",
    "else:\n",
    "    print(\"Model weights have not been loaded from checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_dct_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.equal(initial_dct_weights[param], model.state_dict()[param]) for param in model.state_dict()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "softmax = torch.nn.Softmax(dim = 1)\n",
    "with torch.autograd.no_grad():\n",
    "    for batch in loader_test:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        out = model.forward(batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(out).cpu().detach().numpy().argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que si que carga todo bien... Voy a proceder a hacerlo entero y guardarlo entonces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_gen(test_data, \n",
    "                    model, \n",
    "                    pred_batch, \n",
    "                    device, \n",
    "                    label_type = label_type, \n",
    "                    nclass     = nclass)\n",
    "coorname = ['xbin', 'ybin', 'zbin']\n",
    "\n",
    "if label_type == LabelType.Classification:\n",
    "    tname = 'EventPred'\n",
    "if label_type == LabelType.Segmentation:\n",
    "    tname = 'VoxelPred'\n",
    "with tb.open_file(outfile, 'w') as h5out:\n",
    "    for dct in pred:\n",
    "        if 'coords' in dct:\n",
    "            coords = dct.pop('coords')\n",
    "            dct.update({c:coords[:, i] for i, c in enumerate(coorname)})\n",
    "        prediction = dct.pop('prediction')\n",
    "        dct.update({f'class_{i}':prediction[:, i] for i in range(prediction.shape[1])})\n",
    "\n",
    "        df = pd.DataFrame(dct)\n",
    "        df.to_hdf(outfile, tname, append=True)\n",
    "#Finally we sort the output dataframe \n",
    "df = pd.read_hdf(outfile, tname).sort_values(['file_id', 'dataset_id'])\n",
    "os.remove(outfile)\n",
    "df.to_hdf(outfile, tname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
