{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import os.path as osp\n",
    "from   glob import glob\n",
    "\n",
    "import invisible_cities.io.dst_io as dio\n",
    "\n",
    "import torch\n",
    "from   torch_geometric.data import Data, Dataset\n",
    "from   torch_geometric.data.makedirs import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, root, tag = '0nubb', transform=None, pre_transform=None, pre_filter=None, directed = False, simplify_segclass = False):\n",
    "        self.sort = lambda x: int(x.split('_')[-2])\n",
    "        self.tag = tag\n",
    "        self.directed = directed\n",
    "        self.simplify_segclass = simplify_segclass\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        ''' \n",
    "        Returns a list of the raw files in order (supossing they are beersheba labelled files that have the structure beersheba_label_N_tag.h5)\n",
    "        '''\n",
    "        rfiles = [i.split('/')[-1] for i in glob(self.raw_dir + '/*_{}.h5'.format(self.tag))]\n",
    "        return sorted(rfiles, key = self.sort)\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        '''\n",
    "        Returns a list of the processed files in order (supossing they are stored tensors with the structure data_N.pt)\n",
    "        '''\n",
    "        pfiles = [i.split('/')[-1] for i in glob(self.processed_dir + '/data_*_{}.pt'.format(self.tag))]\n",
    "        return sorted(pfiles, key = self.sort)\n",
    "    \n",
    "    def process(self):\n",
    "        makedirs(self.processed_dir)\n",
    "        already_processed = [self.sort(i) for i in self.processed_file_names]\n",
    "        for raw_path in self.raw_paths:\n",
    "            idx = self.sort(raw_path)\n",
    "            if np.isin(idx, already_processed):\n",
    "                #to avoid processing already processed files\n",
    "                continue\n",
    "            data = graphDataset(raw_path, directed=self.directed, simplify_segclass=self.simplify_segclass)\n",
    "\n",
    "            #if self.pre_filter is not None and not self.pre_filter(data):\n",
    "            #    continue\n",
    "\n",
    "            #if self.pre_transform is not None:\n",
    "            #    data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, f'data_{idx}_{self.tag}.pt'))\n",
    "        \n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}_{self.tag}.pt'))\n",
    "        return data\n",
    "\n",
    "    def join(self):\n",
    "        #print('Joining ', self.processed_file_names)\n",
    "        dataset = []\n",
    "        for processed_path in self.processed_paths:\n",
    "            dataset += torch.load(processed_path)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GENConv, DeepGCNLayer\n",
    "from torch.nn import BatchNorm1d, CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to create a GCN with skip connections using the DeepGCNLayer. I'll use 'res+' structure as it seems to perform better, and for the convolution I'll use the GENeralized Graph Convolution (GENConv), created and tested by the same authors as the skip connections structure.\n",
    "\n",
    "Then, for normalization will be just batch norm, and for activation ReLU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More precisely, it is the DyResGen network from https://arxiv.org/pdf/2006.07739.pdf."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](skip_connections.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeperGCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout):\n",
    "        super(DeeperGCN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        # A list of DeepGCNLayers\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        ############ BUILDING THE LAYERS ##############\n",
    "        ## 1. Use a linear transformation to encode the node features from input_dim to hidden_dim\n",
    "        ## 2. Create a group of num_layers with the DeepGCNLayer for skipping connections using the\n",
    "        ##    GENConv operation \n",
    "        ## 3. Apply a final linear transformation to have the number of features corresponding to the \n",
    "        ##    number of classes per node\n",
    "\n",
    "        self.encoder = torch.nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        for i in range(1, num_layers + 1):\n",
    "            conv = GENConv(hidden_dim, hidden_dim, aggr='softmax',\n",
    "                           t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
    "            norm = torch.nn.BatchNorm1d(hidden_dim)\n",
    "            act = torch.nn.ReLU(inplace=True)\n",
    "\n",
    "            layer = DeepGCNLayer(conv, norm, act, block='res+', dropout=dropout,\n",
    "                                 ckpt_grad=False) #i % 3)\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lay in self.layers:\n",
    "            lay.reset_parameters()\n",
    "        self.encoder.reset_parameters()\n",
    "        self.lin.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        x = self.layers[0].conv(x, edge_index)\n",
    "\n",
    "        for layer in self.layers[1:]:\n",
    "            x = layer(x, edge_index)\n",
    "\n",
    "        x = self.layers[0].act(self.layers[0].norm(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        out = self.lin(x)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, device, optimizer, loss_fn):\n",
    "    # Tell the model it's going to train\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    # Iterate for the batches in the data loader\n",
    "    for batch in loader:\n",
    "        # Pass the batch to device (cuda)\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Zero grad the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass the data to the model\n",
    "        out = model.forward(batch.x.type(torch.float), batch.edge_index) \n",
    "\n",
    "        # Now we pass the output and the labels to the loss function\n",
    "        # We will use nll_loss (negative log likelihood, useful to train C classes bc we can add weights for each class)\n",
    "        # This loss will need input (N, C) target (N); being C = num of classes, N = batch size\n",
    "        \n",
    "        # We read the label, transform into long tensor (needed by this loss function), pass to cuda device and shifted by one \n",
    "        # because for the output the classes are from [0, 6] and for the labels they are [1, 7]\n",
    "        label = batch.y.type(torch.LongTensor).to(device) - 1\n",
    "\n",
    "        # The reshape is needed to pass from a (N, 1) shape (automatically appears when doing\n",
    "        # batch.y), to a (N) shape as we need; the output of the net is already (N, C) if it's properly built\n",
    "        loss = loss_fn(out, torch.reshape(label, (-1,)))\n",
    "        \n",
    "        # Back propagation (compute gradients of the loss with respect to the weights in the model)\n",
    "        loss.backward()\n",
    "        # Gradient descent (update the optimizer)\n",
    "        optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, true):\n",
    "    acc = sum(pred == true) / len(pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(pred, true, nclass = 3):\n",
    "    \"\"\"\n",
    "        Intersection over union is a metric for semantic segmentation.\n",
    "        It returns a IoU value for each class of our input tensors/arrays.\n",
    "    \"\"\"\n",
    "    eps = sys.float_info.epsilon\n",
    "    confusion_matrix = np.zeros((nclass, nclass))\n",
    "\n",
    "    for i in range(len(true)):\n",
    "        confusion_matrix[true[i]][pred[i]] += 1\n",
    "\n",
    "    IoU = []\n",
    "    for i in range(nclass):\n",
    "        IoU.append((confusion_matrix[i, i] + eps) / (sum(confusion_matrix[:, i]) + sum(confusion_matrix[i, :]) - confusion_matrix[i, i] + eps))\n",
    "    return np.array(IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, device):\n",
    "    # Set the model to evaluate\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # Iterate for the batches in the data loader\n",
    "    for batch in loader:\n",
    "        # Put batch into device (cuda)\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Pass the data to the model\n",
    "        with torch.no_grad():\n",
    "            out = model.forward(batch.x.type(torch.float), batch.edge_index)\n",
    "        \n",
    "        # For each node set the maximum argument to pick a class\n",
    "        pred = out.argmax(dim=-1, keepdim=True)  \n",
    "\n",
    "        #Once again, the labels are shifted by 1 to match the prediction positions (explained in train fun)\n",
    "        true = torch.reshape(batch.y, (-1,)).detach().cpu() - 1\n",
    "        \n",
    "        #Append the results to lists\n",
    "        y_pred.append(torch.reshape(pred, (-1,)).detach().cpu())\n",
    "        y_true.append(true)\n",
    "    \n",
    "    #Concatenate the items in the list and transform into array\n",
    "    y_pred = torch.cat(y_pred).numpy()\n",
    "    y_true = torch.cat(y_true).numpy()\n",
    "\n",
    "    #Identify the neighbor segclass with their original segclass to compare each node\n",
    "    label_map = {0:0, 1:1, 2:2, 3:0, 4:1, 5:2, 6:3}\n",
    "    y_pred = np.array([label_map[i] for i in y_pred])\n",
    "    y_true = np.array([label_map[i] for i in y_true])\n",
    "    \n",
    "    # Compare and return an accuracy (number of success nodes / all nodes)\n",
    "    # Not the best, it is better the IoU for segmentation\n",
    "    acc = accuracy(y_pred, y_true)\n",
    "    iou = IoU(y_pred, y_true, nclass=4)\n",
    "    return acc, iou, y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_idx_split(dataset, train_perc):\n",
    "    indices = np.arange(len(dataset))\n",
    "    valid_perc = (1 - train_perc) / 2\n",
    "    random.shuffle(indices)\n",
    "    train_data = torch.tensor(np.sort(indices[:int((len(indices)+1)*train_perc)])) #Remaining 80% to training set\n",
    "    valid_data = torch.tensor(np.sort(indices[int((len(indices)+1)*train_perc):int((len(indices)+1)*(train_perc + valid_perc))]))\n",
    "    test_data = torch.tensor(np.sort(indices[int((len(indices)+1)*(train_perc + valid_perc)):]))\n",
    "    idx_split = {'train':train_data, 'valid':valid_data, 'test':test_data}\n",
    "    return idx_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for the net and the train\n",
    "args = {\n",
    "      'device': device,\n",
    "      'nclass':7,\n",
    "      'num_layers': 25,\n",
    "      'hidden_dim': 30,\n",
    "      'dropout': 0.1,\n",
    "      'lr': 0.001,\n",
    "      'epochs': 100,\n",
    "      'batch_size': 50\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the dataset, index split and data loaders for each case\n",
    "file_path = '/mnt/lustre/scratch/nlsas/home/usc/ie/mpm/NEXT100/labelled_data/0nubb/554mm_voxels/'\n",
    "\n",
    "dataset = Dataset(file_path, '0nubb').join()\n",
    "idx_split = create_idx_split(dataset, 0.8)\n",
    "\n",
    "train_loader = DataLoader([dataset[i] for i in idx_split['train']], batch_size=args['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader([dataset[i] for i in idx_split['valid']], batch_size=args['batch_size'], shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader([dataset[i] for i in idx_split['test']], batch_size=args['batch_size'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_loss(file_names, correct = False):\n",
    "    #correct assigns to the ghost class the desired inverse freq and redistributes the rest\n",
    "    seg = pd.Series(dtype='int')\n",
    "    for f in file_names:\n",
    "        seg = seg.append(dio.load_dst(f, 'DATASET', 'BeershebaVoxels').segclass)\n",
    "    freq = np.bincount(seg - 1, minlength=max(seg))\n",
    "    inv_freq = 1. / freq\n",
    "    inv_freq = inv_freq / sum(inv_freq)\n",
    "    if correct:\n",
    "        redistr = inv_freq[:-1] * (1 - correct) / sum(inv_freq[:-1])\n",
    "        inv_freq = np.append(redistr, correct)\n",
    "    return inv_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_for_weights = glob(file_path + 'raw/*.h5')\n",
    "inv_freq = weight_loss(files_for_weights, correct = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the model with the previous args and set to device\n",
    "model = DeeperGCN(dataset[0].num_features, args['hidden_dim'],\n",
    "                args['nclass'], args['num_layers'],\n",
    "                args['dropout']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set true if we want to train in the next cell\n",
    "start_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 01, Loss: 1.8163, Train: 4.53%, Valid: 3.59% Test: 5.04%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 02, Loss: 1.7844, Train: 77.27%, Valid: 77.56% Test: 77.03%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 03, Loss: 1.7395, Train: 77.27%, Valid: 77.56% Test: 77.03%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 04, Loss: 1.7838, Train: 77.27%, Valid: 77.57% Test: 77.04%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 05, Loss: 1.7481, Train: 77.27%, Valid: 77.57% Test: 77.04%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 06, Loss: 1.6568, Train: 77.27%, Valid: 77.57% Test: 77.04%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 07, Loss: 1.6497, Train: 77.27%, Valid: 77.57% Test: 77.04%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 08, Loss: 1.6351, Train: 77.27%, Valid: 77.57% Test: 77.04%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 09, Loss: 1.6146, Train: 46.74%, Valid: 48.01% Test: 47.05%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 10, Loss: 1.5779, Train: 20.20%, Valid: 22.30% Test: 19.60%\n",
      "Blob IoU train: 18.19%, Blob IoU valid: 19.06%, Blob IoU test: 18.03%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 11, Loss: 1.6061, Train: 74.18%, Valid: 74.31% Test: 74.25%\n",
      "Blob IoU train: 1.77%, Blob IoU valid: 0.53%, Blob IoU test: 3.49%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 12, Loss: 1.5777, Train: 7.89%, Valid: 6.68% Test: 8.70%\n",
      "Blob IoU train: 16.59%, Blob IoU valid: 14.41%, Blob IoU test: 18.35%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 13, Loss: 1.5940, Train: 4.54%, Valid: 3.59% Test: 5.05%\n",
      "Blob IoU train: 0.07%, Blob IoU valid: 0.00%, Blob IoU test: 0.06%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 14, Loss: 1.5698, Train: 74.49%, Valid: 74.61% Test: 73.77%\n",
      "Blob IoU train: 0.75%, Blob IoU valid: 0.59%, Blob IoU test: 3.62%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 15, Loss: 1.6334, Train: 72.97%, Valid: 74.38% Test: 73.38%\n",
      "Blob IoU train: 23.17%, Blob IoU valid: 22.94%, Blob IoU test: 24.33%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 16, Loss: 1.5716, Train: 75.77%, Valid: 77.61% Test: 75.85%\n",
      "Blob IoU train: 20.19%, Blob IoU valid: 20.67%, Blob IoU test: 23.68%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 17, Loss: 1.5209, Train: 49.31%, Valid: 53.09% Test: 52.80%\n",
      "Blob IoU train: 30.62%, Blob IoU valid: 33.09%, Blob IoU test: 28.01%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 18, Loss: 1.5809, Train: 57.29%, Valid: 60.02% Test: 60.26%\n",
      "Blob IoU train: 28.48%, Blob IoU valid: 30.35%, Blob IoU test: 27.13%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 19, Loss: 1.5878, Train: 16.09%, Valid: 15.87% Test: 16.59%\n",
      "Blob IoU train: 23.46%, Blob IoU valid: 23.16%, Blob IoU test: 22.93%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 20, Loss: 1.5382, Train: 33.59%, Valid: 30.37% Test: 30.57%\n",
      "Blob IoU train: 5.23%, Blob IoU valid: 1.89%, Blob IoU test: 8.74%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 21, Loss: 1.5247, Train: 65.95%, Valid: 64.16% Test: 65.70%\n",
      "Blob IoU train: 1.45%, Blob IoU valid: 0.47%, Blob IoU test: 3.59%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 22, Loss: 1.5707, Train: 32.27%, Valid: 36.63% Test: 33.49%\n",
      "Blob IoU train: 17.54%, Blob IoU valid: 19.28%, Blob IoU test: 18.68%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 23, Loss: 1.5472, Train: 36.80%, Valid: 40.76% Test: 38.27%\n",
      "Blob IoU train: 22.73%, Blob IoU valid: 24.30%, Blob IoU test: 22.35%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 24, Loss: 1.6223, Train: 72.29%, Valid: 71.40% Test: 72.68%\n",
      "Blob IoU train: 2.91%, Blob IoU valid: 2.05%, Blob IoU test: 6.95%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 25, Loss: 1.5477, Train: 22.21%, Valid: 23.60% Test: 19.42%\n",
      "Blob IoU train: 28.71%, Blob IoU valid: 30.81%, Blob IoU test: 26.94%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 26, Loss: 1.5386, Train: 77.28%, Valid: 77.50% Test: 77.53%\n",
      "Blob IoU train: 0.67%, Blob IoU valid: 0.41%, Blob IoU test: 3.73%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 27, Loss: 1.5315, Train: 64.62%, Valid: 62.39% Test: 64.15%\n",
      "Blob IoU train: 0.22%, Blob IoU valid: 0.00%, Blob IoU test: 2.75%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 28, Loss: 1.5390, Train: 32.47%, Valid: 30.70% Test: 31.40%\n",
      "Blob IoU train: 6.25%, Blob IoU valid: 1.14%, Blob IoU test: 10.33%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 29, Loss: 1.5288, Train: 48.58%, Valid: 45.44% Test: 43.12%\n",
      "Blob IoU train: 0.00%, Blob IoU valid: 0.00%, Blob IoU test: 0.00%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 30, Loss: 1.5726, Train: 24.04%, Valid: 23.98% Test: 23.18%\n",
      "Blob IoU train: 22.82%, Blob IoU valid: 24.44%, Blob IoU test: 21.89%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 31, Loss: 1.5108, Train: 24.75%, Valid: 25.23% Test: 24.08%\n",
      "Blob IoU train: 22.78%, Blob IoU valid: 24.40%, Blob IoU test: 22.33%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 32, Loss: 1.5091, Train: 9.21%, Valid: 7.34% Test: 9.97%\n",
      "Blob IoU train: 9.54%, Blob IoU valid: 3.14%, Blob IoU test: 14.13%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 33, Loss: 1.5158, Train: 19.79%, Valid: 21.93% Test: 18.41%\n",
      "Blob IoU train: 22.40%, Blob IoU valid: 24.04%, Blob IoU test: 22.02%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 34, Loss: 1.5421, Train: 21.67%, Valid: 21.26% Test: 18.79%\n",
      "Blob IoU train: 28.13%, Blob IoU valid: 30.46%, Blob IoU test: 23.74%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 35, Loss: 1.5501, Train: 47.08%, Valid: 43.34% Test: 41.39%\n",
      "Blob IoU train: 9.94%, Blob IoU valid: 6.64%, Blob IoU test: 15.40%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 36, Loss: 1.5301, Train: 8.01%, Valid: 7.18% Test: 10.28%\n",
      "Blob IoU train: 3.96%, Blob IoU valid: 4.17%, Blob IoU test: 8.28%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 37, Loss: 1.5233, Train: 20.13%, Valid: 22.22% Test: 19.70%\n",
      "Blob IoU train: 19.58%, Blob IoU valid: 20.42%, Blob IoU test: 19.60%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 38, Loss: 1.5069, Train: 17.78%, Valid: 17.56% Test: 16.43%\n",
      "Blob IoU train: 24.24%, Blob IoU valid: 25.74%, Blob IoU test: 23.87%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 39, Loss: 1.5564, Train: 36.67%, Valid: 36.18% Test: 35.91%\n",
      "Blob IoU train: 24.08%, Blob IoU valid: 24.88%, Blob IoU test: 20.63%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 40, Loss: 1.4535, Train: 10.24%, Valid: 9.61% Test: 11.48%\n",
      "Blob IoU train: 23.18%, Blob IoU valid: 24.53%, Blob IoU test: 25.13%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 41, Loss: 1.4790, Train: 10.71%, Valid: 10.31% Test: 12.68%\n",
      "Blob IoU train: 20.95%, Blob IoU valid: 22.79%, Blob IoU test: 23.56%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 42, Loss: 1.5034, Train: 17.85%, Valid: 17.93% Test: 16.85%\n",
      "Blob IoU train: 22.93%, Blob IoU valid: 24.39%, Blob IoU test: 22.65%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 43, Loss: 1.4859, Train: 73.00%, Valid: 74.14% Test: 73.34%\n",
      "Blob IoU train: 22.44%, Blob IoU valid: 22.67%, Blob IoU test: 23.65%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 44, Loss: 1.4242, Train: 17.87%, Valid: 18.06% Test: 18.08%\n",
      "Blob IoU train: 18.32%, Blob IoU valid: 18.93%, Blob IoU test: 18.14%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 45, Loss: 1.5091, Train: 15.18%, Valid: 15.49% Test: 13.88%\n",
      "Blob IoU train: 28.36%, Blob IoU valid: 31.22%, Blob IoU test: 25.29%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 46, Loss: 1.4802, Train: 17.84%, Valid: 18.13% Test: 16.95%\n",
      "Blob IoU train: 21.93%, Blob IoU valid: 23.53%, Blob IoU test: 21.44%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 47, Loss: 1.5401, Train: 17.78%, Valid: 17.86% Test: 16.52%\n",
      "Blob IoU train: 24.35%, Blob IoU valid: 25.58%, Blob IoU test: 23.70%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 48, Loss: 1.5016, Train: 39.87%, Valid: 41.91% Test: 43.13%\n",
      "Blob IoU train: 23.67%, Blob IoU valid: 25.49%, Blob IoU test: 23.32%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 49, Loss: 1.4687, Train: 17.86%, Valid: 17.92% Test: 16.75%\n",
      "Blob IoU train: 22.46%, Blob IoU valid: 24.01%, Blob IoU test: 21.98%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 50, Loss: 1.4131, Train: 18.11%, Valid: 18.69% Test: 17.74%\n",
      "Blob IoU train: 18.12%, Blob IoU valid: 18.69%, Blob IoU test: 17.75%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 51, Loss: 1.4946, Train: 17.90%, Valid: 18.58% Test: 17.66%\n",
      "Blob IoU train: 18.03%, Blob IoU valid: 18.63%, Blob IoU test: 17.74%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 52, Loss: 1.5051, Train: 18.03%, Valid: 18.36% Test: 17.83%\n",
      "Blob IoU train: 20.56%, Blob IoU valid: 21.42%, Blob IoU test: 20.22%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 53, Loss: 1.5429, Train: 19.72%, Valid: 17.88% Test: 20.89%\n",
      "Blob IoU train: 12.75%, Blob IoU valid: 11.86%, Blob IoU test: 13.38%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 54, Loss: 1.4769, Train: 6.34%, Valid: 5.39% Test: 7.16%\n",
      "Blob IoU train: 10.00%, Blob IoU valid: 8.99%, Blob IoU test: 11.84%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 55, Loss: 1.4857, Train: 17.15%, Valid: 17.08% Test: 14.94%\n",
      "Blob IoU train: 25.72%, Blob IoU valid: 27.89%, Blob IoU test: 23.93%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 56, Loss: 1.4632, Train: 12.59%, Valid: 11.96% Test: 12.08%\n",
      "Blob IoU train: 26.21%, Blob IoU valid: 27.33%, Blob IoU test: 24.16%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 57, Loss: 1.4122, Train: 17.82%, Valid: 18.20% Test: 18.18%\n",
      "Blob IoU train: 18.89%, Blob IoU valid: 19.48%, Blob IoU test: 18.68%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 58, Loss: 1.4370, Train: 18.11%, Valid: 18.69% Test: 17.74%\n",
      "Blob IoU train: 18.12%, Blob IoU valid: 18.69%, Blob IoU test: 17.75%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 59, Loss: 1.4916, Train: 18.11%, Valid: 18.69% Test: 17.74%\n",
      "Blob IoU train: 18.12%, Blob IoU valid: 18.69%, Blob IoU test: 17.75%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 60, Loss: 1.4295, Train: 17.26%, Valid: 17.44% Test: 14.79%\n",
      "Blob IoU train: 26.59%, Blob IoU valid: 28.57%, Blob IoU test: 24.70%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 61, Loss: 1.5574, Train: 35.18%, Valid: 33.49% Test: 32.23%\n",
      "Blob IoU train: 17.30%, Blob IoU valid: 17.64%, Blob IoU test: 23.61%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 62, Loss: 1.4630, Train: 13.40%, Valid: 12.87% Test: 12.84%\n",
      "Blob IoU train: 28.19%, Blob IoU valid: 28.79%, Blob IoU test: 26.20%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 63, Loss: 1.4681, Train: 10.59%, Valid: 9.56% Test: 12.55%\n",
      "Blob IoU train: 17.46%, Blob IoU valid: 17.14%, Blob IoU test: 19.08%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 64, Loss: 1.4324, Train: 7.28%, Valid: 6.40% Test: 8.09%\n",
      "Blob IoU train: 13.53%, Blob IoU valid: 13.20%, Blob IoU test: 16.02%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 65, Loss: 1.5057, Train: 8.65%, Valid: 7.57% Test: 10.18%\n",
      "Blob IoU train: 18.79%, Blob IoU valid: 17.82%, Blob IoU test: 23.13%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 66, Loss: 1.4379, Train: 18.84%, Valid: 18.49% Test: 17.50%\n",
      "Blob IoU train: 24.65%, Blob IoU valid: 26.49%, Blob IoU test: 24.52%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 67, Loss: 1.4520, Train: 18.11%, Valid: 18.37% Test: 17.93%\n",
      "Blob IoU train: 18.09%, Blob IoU valid: 18.63%, Blob IoU test: 17.67%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 68, Loss: 1.4070, Train: 17.90%, Valid: 18.24% Test: 18.47%\n",
      "Blob IoU train: 19.61%, Blob IoU valid: 20.49%, Blob IoU test: 19.70%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 69, Loss: 1.4235, Train: 17.92%, Valid: 18.30% Test: 18.38%\n",
      "Blob IoU train: 19.39%, Blob IoU valid: 20.10%, Blob IoU test: 19.35%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 70, Loss: 1.4140, Train: 16.34%, Valid: 16.82% Test: 16.11%\n",
      "Blob IoU train: 16.69%, Blob IoU valid: 17.40%, Blob IoU test: 16.11%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 71, Loss: 1.4770, Train: 17.95%, Valid: 18.30% Test: 17.44%\n",
      "Blob IoU train: 21.28%, Blob IoU valid: 22.76%, Blob IoU test: 20.42%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 72, Loss: 1.3796, Train: 35.00%, Valid: 38.04% Test: 37.62%\n",
      "Blob IoU train: 4.97%, Blob IoU valid: 5.79%, Blob IoU test: 2.94%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 73, Loss: 1.4368, Train: 44.12%, Valid: 43.70% Test: 47.71%\n",
      "Blob IoU train: 16.57%, Blob IoU valid: 14.18%, Blob IoU test: 17.66%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 74, Loss: 1.4130, Train: 16.81%, Valid: 16.73% Test: 15.08%\n",
      "Blob IoU train: 22.86%, Blob IoU valid: 23.68%, Blob IoU test: 20.29%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 75, Loss: 1.4049, Train: 22.89%, Valid: 19.46% Test: 22.32%\n",
      "Blob IoU train: 19.78%, Blob IoU valid: 17.95%, Blob IoU test: 23.49%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 76, Loss: 1.3512, Train: 21.97%, Valid: 21.70% Test: 25.80%\n",
      "Blob IoU train: 10.45%, Blob IoU valid: 8.20%, Blob IoU test: 14.71%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 77, Loss: 1.3981, Train: 41.24%, Valid: 42.07% Test: 44.76%\n",
      "Blob IoU train: 9.66%, Blob IoU valid: 9.83%, Blob IoU test: 8.17%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 78, Loss: 1.4827, Train: 17.95%, Valid: 18.57% Test: 18.25%\n",
      "Blob IoU train: 19.01%, Blob IoU valid: 19.54%, Blob IoU test: 18.80%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 79, Loss: 1.4122, Train: 70.94%, Valid: 71.33% Test: 71.35%\n",
      "Blob IoU train: 15.67%, Blob IoU valid: 15.00%, Blob IoU test: 14.17%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 80, Loss: 1.4555, Train: 10.26%, Valid: 9.46% Test: 10.30%\n",
      "Blob IoU train: 5.85%, Blob IoU valid: 6.93%, Blob IoU test: 5.21%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 81, Loss: 1.4440, Train: 8.64%, Valid: 7.43% Test: 9.70%\n",
      "Blob IoU train: 18.63%, Blob IoU valid: 16.93%, Blob IoU test: 21.17%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 82, Loss: 1.5037, Train: 15.78%, Valid: 16.24% Test: 14.24%\n",
      "Blob IoU train: 27.27%, Blob IoU valid: 29.77%, Blob IoU test: 27.44%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 83, Loss: 1.4039, Train: 7.94%, Valid: 6.47% Test: 10.31%\n",
      "Blob IoU train: 10.54%, Blob IoU valid: 9.17%, Blob IoU test: 15.38%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 84, Loss: 1.4190, Train: 45.73%, Valid: 43.41% Test: 43.02%\n",
      "Blob IoU train: 14.59%, Blob IoU valid: 14.29%, Blob IoU test: 16.15%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 85, Loss: 1.3956, Train: 5.87%, Valid: 4.92% Test: 7.39%\n",
      "Blob IoU train: 4.09%, Blob IoU valid: 4.32%, Blob IoU test: 6.16%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 86, Loss: 1.4319, Train: 5.10%, Valid: 4.87% Test: 6.76%\n",
      "Blob IoU train: 3.36%, Blob IoU valid: 3.88%, Blob IoU test: 5.73%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 87, Loss: 1.4426, Train: 18.74%, Valid: 17.88% Test: 14.77%\n",
      "Blob IoU train: 26.74%, Blob IoU valid: 28.33%, Blob IoU test: 23.54%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 88, Loss: 1.4055, Train: 17.76%, Valid: 18.10% Test: 18.20%\n",
      "Blob IoU train: 19.72%, Blob IoU valid: 20.71%, Blob IoU test: 19.89%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 89, Loss: 1.4330, Train: 8.86%, Valid: 7.20% Test: 10.53%\n",
      "Blob IoU train: 9.88%, Blob IoU valid: 8.34%, Blob IoU test: 12.37%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 90, Loss: 1.3498, Train: 18.23%, Valid: 17.72% Test: 15.02%\n",
      "Blob IoU train: 25.83%, Blob IoU valid: 27.11%, Blob IoU test: 22.96%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 91, Loss: 1.4281, Train: 20.71%, Valid: 20.81% Test: 19.79%\n",
      "Blob IoU train: 19.90%, Blob IoU valid: 20.60%, Blob IoU test: 19.16%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 92, Loss: 1.3883, Train: 32.11%, Valid: 30.27% Test: 32.35%\n",
      "Blob IoU train: 8.90%, Blob IoU valid: 5.30%, Blob IoU test: 12.71%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 93, Loss: 1.3382, Train: 4.95%, Valid: 4.33% Test: 4.85%\n",
      "Blob IoU train: 2.60%, Blob IoU valid: 3.01%, Blob IoU test: 1.58%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 94, Loss: 1.4054, Train: 5.69%, Valid: 4.59% Test: 6.46%\n",
      "Blob IoU train: 6.18%, Blob IoU valid: 5.19%, Blob IoU test: 7.10%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 95, Loss: 1.4192, Train: 9.10%, Valid: 7.92% Test: 10.02%\n",
      "Blob IoU train: 20.08%, Blob IoU valid: 18.92%, Blob IoU test: 22.47%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 96, Loss: 1.4269, Train: 12.62%, Valid: 11.80% Test: 13.41%\n",
      "Blob IoU train: 15.28%, Blob IoU valid: 14.76%, Blob IoU test: 14.68%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 97, Loss: 1.4035, Train: 6.60%, Valid: 6.71% Test: 7.81%\n",
      "Blob IoU train: 6.78%, Blob IoU valid: 7.81%, Blob IoU test: 8.40%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 98, Loss: 1.4053, Train: 13.92%, Valid: 13.37% Test: 12.88%\n",
      "Blob IoU train: 29.09%, Blob IoU valid: 29.80%, Blob IoU test: 25.89%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 99, Loss: 1.4793, Train: 52.49%, Valid: 48.50% Test: 47.80%\n",
      "Blob IoU train: 26.23%, Blob IoU valid: 26.69%, Blob IoU test: 21.74%, \n",
      "Training...\n",
      "Evaluating...\n",
      "Epoch: 100, Loss: 1.3505, Train: 16.59%, Valid: 16.17% Test: 15.97%\n",
      "Blob IoU train: 22.44%, Blob IoU valid: 23.34%, Blob IoU test: 21.73%, \n"
     ]
    }
   ],
   "source": [
    "if start_train:\n",
    "  # Start from zero the model (not using a trained model)\n",
    "  model.reset_parameters()\n",
    "\n",
    "  # Initiate the optimizer with the model parameters and a learning rate\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "\n",
    "  # Pick the loss function\n",
    "  loss_fn = CrossEntropyLoss(weight=torch.Tensor(inv_freq).to(device)) #torch.nn.NLLLoss(weight=torch.Tensor(inv_freq).to(device)) #\n",
    "\n",
    "  best_model = None\n",
    "  best_valid_acc = 0\n",
    "\n",
    "  # Iterate on the number of epochs\n",
    "  pred = []\n",
    "  true = []\n",
    "  for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    # Train the model with the fucntion\n",
    "    print('Training...')\n",
    "    loss = train(model, train_loader, device, optimizer, loss_fn)\n",
    "\n",
    "    #Evaluate the model with the function and for the 3 sets of data\n",
    "    print('Evaluating...')\n",
    "    train_acc, train_iou, _, _ = eval(model, train_loader, device)\n",
    "    val_acc, val_iou, y_pred, y_true = eval(model, valid_loader, device)\n",
    "    test_acc, test_iou, _, _ = eval(model, test_loader, device)\n",
    "    #pred.append(y_pred)\n",
    "    #true.append(y_true)\n",
    "    # Store the model if the validation accuracy improved\n",
    "    if val_acc > best_valid_acc:\n",
    "        best_valid_acc = val_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    # Print the important variables for epoch\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_acc:.2f}%, '\n",
    "          f'Valid: {100 * val_acc:.2f}% '\n",
    "          f'Test: {100 * test_acc:.2f}%')\n",
    "    print(f'Blob IoU train: {100 * train_iou[-2]:.2f}%, '\n",
    "          f'Blob IoU valid: {100 * val_iou[-2]:.2f}%, '\n",
    "          f'Blob IoU test: {100 * test_iou[-2]:.2f}%, ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Train: 75.77%, Valid: 77.61% Test: 75.85%\n",
      "Best model IoU blob: Train: 20.19%, Valid: 20.67% Test: 23.68%\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_iou, _, _ = eval(best_model, train_loader, device)\n",
    "valid_acc, valid_iou, _, _ = eval(best_model, valid_loader, device)\n",
    "test_acc, test_iou, _, _  = eval(best_model, test_loader, device)\n",
    "\n",
    "print(f'Best model: '\n",
    "      f'Train: {100 * train_acc:.2f}%, '\n",
    "      f'Valid: {100 * valid_acc:.2f}% '\n",
    "      f'Test: {100 * test_acc:.2f}%')\n",
    "print(f'Best model IoU blob: '\n",
    "      f'Train: {100 * train_iou[-2]:.2f}%, '\n",
    "      f'Valid: {100 * valid_iou[-2]:.2f}% '\n",
    "      f'Test: {100 * test_iou[-2]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
